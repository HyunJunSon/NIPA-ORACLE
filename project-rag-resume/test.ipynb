{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701cb5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_model.py\n",
    "import os\n",
    "import psycopg\n",
    "from typing import List, Union\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredImageLoader,\n",
    "    Docx2txtLoader\n",
    ")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class RAGBot:\n",
    "    def __init__(self, file_paths: Union[str, List[str]], collection_name: str = \"rag-resume\"):\n",
    "        \"\"\"\n",
    "        RAG ì±—ë´‡ ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            file_paths: ë‹¨ì¼ íŒŒì¼ ê²½ë¡œ(str) ë˜ëŠ” íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸(List[str])\n",
    "            collection_name: ë²¡í„°ìŠ¤í† ì–´ ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "        \"\"\"\n",
    "        load_dotenv()\n",
    "        \n",
    "        # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        if isinstance(file_paths, str):\n",
    "            self.file_paths = [file_paths]\n",
    "        else:\n",
    "            self.file_paths = file_paths\n",
    "            \n",
    "        self.collection_name = collection_name\n",
    "        self.documents = []\n",
    "\n",
    "        print(f\"\\n[1] ë¬¸ì„œ ë¡œë“œ ({len(self.file_paths)}ê°œ íŒŒì¼)\")\n",
    "        self._load_all_documents()\n",
    "        print(f\"âœ… ì´ {len(self.documents)}ê°œì˜ ë¬¸ì„œ/í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "        print(\"\\n[2] ë¬¸ì„œ ë¶„í• \")\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "        self.splits = splitter.split_documents(self.documents)\n",
    "        print(f\"âœ… ì´ {len(self.splits)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ\")\n",
    "\n",
    "        print(\"\\n[3] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ\")\n",
    "        self.embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "        print(\"\\n[4] Postgres ì—°ê²°\")\n",
    "        self.connection_string = self._setup_db()\n",
    "        print(\"âœ… Postgres ì—°ê²° ë° vector extension í™•ì¸ ì™„ë£Œ\")\n",
    "\n",
    "        print(\"\\n[5] ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\")\n",
    "        self.vectorstore = PGVector.from_documents(\n",
    "            documents=self.splits,\n",
    "            embedding=self.embeddings_model,\n",
    "            collection_name=self.collection_name,\n",
    "            connection=self.connection_string,\n",
    "            pre_delete_collection=True\n",
    "        )\n",
    "        print(f\"âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ ({len(self.splits)}ê°œ ì²­í¬)\")\n",
    "\n",
    "        print(\"\\n[6] ê²€ìƒ‰ê¸° ìƒì„±\")\n",
    "        self.retriever = self.vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 5}  # ë‹¤ì¤‘ íŒŒì¼ì´ë¯€ë¡œ k ì¦ê°€\n",
    "        )\n",
    "\n",
    "        print(\"\\n[7] í”„ë¡¬í”„íŠ¸ êµ¬ì„±\")\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"ë‹¹ì‹ ì€ ì´ë ¥ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "                ì•„ë˜ ì œê³µëœ ê°œì¸ ì •ë³´(Context)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "                \n",
    "                **ì¤‘ìš” ê·œì¹™:**\n",
    "                1. ë¬¸ë§¥ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n",
    "                2. ì´ë ¥ì„œ í•­ëª©ì„ ì •ë¦¬í•  ë•ŒëŠ” ë‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”:\n",
    "                   ### í•­ëª©ëª…\n",
    "                   ë‚´ìš©\n",
    "                3. ì—¬ëŸ¬ í•­ëª©ì„ í•œ ë²ˆì— ì œê³µí•  ë•ŒëŠ” ê° í•­ëª©ì„ ### ìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.\n",
    "                4. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ \"ì œê³µëœ ìë£Œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.\n",
    "                5. ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "                ê°œì¸ ì •ë³´ ë¬¸ë§¥:\n",
    "                {context}\n",
    "                \"\"\"\n",
    "            ),\n",
    "            (\"human\", \"{question}\")\n",
    "        ])\n",
    "\n",
    "        print(\"\\n[8] LLM ì„¤ì •\")\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "        print(\"\\n[9] RAG ì²´ì¸ êµ¬ì„±\")\n",
    "        self.rag_chain = self._create_chain()\n",
    "        print(\"âœ… RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ\\n\")\n",
    "\n",
    "    def _load_all_documents(self):\n",
    "        \"\"\"ëª¨ë“  íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ documents ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\"\"\"\n",
    "        for file_path in self.file_paths:\n",
    "            try:\n",
    "                file_ext = Path(file_path).suffix.lower()\n",
    "                file_name = Path(file_path).name\n",
    "                \n",
    "                print(f\"  ğŸ“„ ë¡œë”© ì¤‘: {file_name}\")\n",
    "                \n",
    "                # íŒŒì¼ íƒ€ì…ë³„ ë¡œë” ì„ íƒ\n",
    "                if file_ext == '.pdf':\n",
    "                    loader = PyPDFLoader(file_path)\n",
    "                    docs = loader.load()\n",
    "                    \n",
    "                elif file_ext == '.txt':\n",
    "                    loader = TextLoader(file_path, encoding='utf-8')\n",
    "                    docs = loader.load()\n",
    "                    \n",
    "                elif file_ext in ['.docx', '.doc']:\n",
    "                    loader = Docx2txtLoader(file_path)\n",
    "                    docs = loader.load()\n",
    "                    \n",
    "                elif file_ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:\n",
    "                    # ì´ë¯¸ì§€ëŠ” OCRì„ í†µí•´ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "                    try:\n",
    "                        loader = UnstructuredImageLoader(file_path)\n",
    "                        docs = loader.load()\n",
    "                    except Exception as e:\n",
    "                        print(f\"    âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ({file_name}): {e}\")\n",
    "                        # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ì‹œ íŒŒì¼ëª…ê³¼ ê²½ë¡œë§Œ ì €ì¥\n",
    "                        docs = [Document(\n",
    "                            page_content=f\"ì´ë¯¸ì§€ íŒŒì¼: {file_name}\",\n",
    "                            metadata={\"source\": file_path, \"type\": \"image\"}\n",
    "                        )]\n",
    "                else:\n",
    "                    print(f\"    âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}\")\n",
    "                    continue\n",
    "                \n",
    "                # ë©”íƒ€ë°ì´í„°ì— íŒŒì¼ëª… ì¶”ê°€\n",
    "                for doc in docs:\n",
    "                    if \"source\" not in doc.metadata:\n",
    "                        doc.metadata[\"source\"] = file_path\n",
    "                    doc.metadata[\"filename\"] = file_name\n",
    "                \n",
    "                self.documents.extend(docs)\n",
    "                print(f\"    âœ… {len(docs)}ê°œ ë¬¸ì„œ/í˜ì´ì§€ ë¡œë“œë¨\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_name}): {e}\")\n",
    "                continue\n",
    "\n",
    "    def _setup_db(self):\n",
    "        \"\"\"PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •\"\"\"\n",
    "        DB_CONFIG = {\n",
    "            'host': os.getenv(\"DB_HOST\"),\n",
    "            'port': 5432,\n",
    "            'dbname': os.getenv('DB_NAME'),\n",
    "            'user': os.getenv('DB_USER'),\n",
    "            'password': os.getenv('DB_PASS'),\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            conn = psycopg.connect(**DB_CONFIG)\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "            conn.commit()\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Postgres ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "        return (\n",
    "            f\"postgresql+psycopg://{DB_CONFIG['user']}:{DB_CONFIG['password']}@\"\n",
    "            f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}\"\n",
    "        )\n",
    "\n",
    "    def _create_chain(self):\n",
    "        \"\"\"RAG ì²´ì¸ ìƒì„±\"\"\"\n",
    "        def format_docs(docs):\n",
    "            formatted = []\n",
    "            for idx, doc in enumerate(docs, 1):\n",
    "                source = doc.metadata.get('filename', doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ'))\n",
    "                formatted.append(f\"[ì¶œì²˜: {source}]\\n{doc.page_content}\")\n",
    "            return \"\\n\\n---\\n\\n\".join(formatted)\n",
    "\n",
    "        return (\n",
    "            {\n",
    "                \"context\": self.retriever | format_docs,\n",
    "                \"question\": RunnablePassthrough()\n",
    "            }\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def ask(self, question: str) -> str:\n",
    "        \"\"\"RAG ì§ˆì˜ ì‹¤í–‰\"\"\"\n",
    "        try:\n",
    "            return self.rag_chain.invoke(question)\n",
    "        except Exception as e:\n",
    "            return f\"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "    \n",
    "    def get_loaded_files_info(self) -> dict:\n",
    "        \"\"\"ë¡œë“œëœ íŒŒì¼ ì •ë³´ ë°˜í™˜\"\"\"\n",
    "        return {\n",
    "            \"total_files\": len(self.file_paths),\n",
    "            \"total_documents\": len(self.documents),\n",
    "            \"total_chunks\": len(self.splits),\n",
    "            \"files\": [Path(fp).name for fp in self.file_paths]\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (oracle-langchain)",
   "language": "python",
   "name": "oracle-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
