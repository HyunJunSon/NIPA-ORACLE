# rag_model.py
import os
import psycopg
import fitz  # PyMuPDF
from typing import List, Union
from pathlib import Path
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_postgres import PGVector
from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredImageLoader,
    Docx2txtLoader
)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document


def extract_images_from_pdf(pdf_path: str, output_dir: str = "data/pic-data/") -> List[str]:
    """
    PDFì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ì—¬ output_dirì— ì €ì¥
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        output_dir: ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬
    
    Returns:
        ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    pdf_document = fitz.open(pdf_path)
    saved_images = []
    file_name = Path(pdf_path).stem  # í™•ì¥ì ì œì™¸í•œ íŒŒì¼ëª…
    
    for page_index in range(len(pdf_document)):
        page = pdf_document[page_index]
        images = page.get_images(full=True)
        print(f"í˜ì´ì§€ {page_index}: {len(images)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
        
        for img_index, img in enumerate(images):
            try:
                xref = img[0]
                base_image = pdf_document.extract_image(xref)
                image_bytes = base_image["image"]
                
                # íŒŒì¼ëª… ìƒì„±: ì›ë³¸íŒŒì¼ëª…_í˜ì´ì§€ë²ˆí˜¸_ì´ë¯¸ì§€ë²ˆí˜¸.í™•ì¥ì
                image_ext = base_image["ext"]
                filename = f"{file_name}_page{page_index}_img{img_index}.{image_ext}"
                filepath = os.path.join(output_dir, filename)
                
                with open(filepath, "wb") as f:
                    f.write(image_bytes)
                print(f"âœ… {filename} ì €ì¥ ì™„ë£Œ")
                saved_images.append(filepath)
            except Exception as e:
                print(f"âŒ ì—ëŸ¬: {e}")
    
    pdf_document.close()
    return saved_images


class RAGBot:
    def __init__(self, file_paths: Union[str, List[str]], collection_name: str = "rag-resume"):
        """
        RAG ì±—ë´‡ ì´ˆê¸°í™”
        
        Args:
            file_paths: ë‹¨ì¼ íŒŒì¼ ê²½ë¡œ(str) ë˜ëŠ” íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸(List[str])
            collection_name: ë²¡í„°ìŠ¤í† ì–´ ì»¬ë ‰ì…˜ ì´ë¦„
        """
        load_dotenv()
        
        # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if isinstance(file_paths, str):
            self.file_paths = [file_paths]
        else:
            self.file_paths = file_paths
            
        self.collection_name = collection_name
        self.documents = []

        print(f"\n[1] ë¬¸ì„œ ë¡œë“œ ({len(self.file_paths)}ê°œ íŒŒì¼)")
        self._load_all_documents()
        print(f"âœ… ì´ {len(self.documents)}ê°œì˜ ë¬¸ì„œ/í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")

        print("\n[2] ë¬¸ì„œ ë¶„í• ")
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        self.splits = splitter.split_documents(self.documents)
        print(f"âœ… ì´ {len(self.splits)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")

        print("\n[3] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ")
        self.embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")

        print("\n[4] Postgres ì—°ê²°")
        self.connection_string = self._setup_db()
        print("âœ… Postgres ì—°ê²° ë° vector extension í™•ì¸ ì™„ë£Œ")

        print("\n[5] ë²¡í„°ìŠ¤í† ì–´ ìƒì„±")
        self.vectorstore = PGVector.from_documents(
            documents=self.splits,
            embedding=self.embeddings_model,
            collection_name=self.collection_name,
            connection=self.connection_string,
            pre_delete_collection=True
        )
        print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ ({len(self.splits)}ê°œ ì²­í¬)")

        print("\n[6] ê²€ìƒ‰ê¸° ìƒì„±")
        self.retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 5}  # ë‹¤ì¤‘ íŒŒì¼ì´ë¯€ë¡œ k ì¦ê°€
        )

        print("\n[7] í”„ë¡¬í”„íŠ¸ êµ¬ì„±")
        self.prompt = ChatPromptTemplate.from_messages([
            (
                "system",
                """ë‹¹ì‹ ì€ ì´ë ¥ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                ì•„ë˜ ì œê³µëœ ê°œì¸ ì •ë³´(Context)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
                
                **ì¤‘ìš” ê·œì¹™:**
                1. ë¬¸ë§¥ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
                2. ì´ë ¥ì„œ í•­ëª©ì„ ì •ë¦¬í•  ë•ŒëŠ” ë‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”:
                   ### í•­ëª©ëª…
                   ë‚´ìš©
                3. ì—¬ëŸ¬ í•­ëª©ì„ í•œ ë²ˆì— ì œê³µí•  ë•ŒëŠ” ê° í•­ëª©ì„ ### ìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
                4. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ "ì œê³µëœ ìë£Œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
                5. ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

                ê°œì¸ ì •ë³´ ë¬¸ë§¥:
                {context}
                """
            ),
            ("human", "{question}")
        ])

        print("\n[8] LLM ì„¤ì •")
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

        print("\n[9] RAG ì²´ì¸ êµ¬ì„±")
        self.rag_chain = self._create_chain()
        print("âœ… RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ\n")

    def _load_all_documents(self):
        """ëª¨ë“  íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ documents ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"""
        for file_path in self.file_paths:
            try:
                file_ext = Path(file_path).suffix.lower()
                file_name = Path(file_path).name
                
                print(f"  ğŸ“„ ë¡œë”© ì¤‘: {file_name}")
                
                # íŒŒì¼ íƒ€ì…ë³„ ë¡œë” ì„ íƒ
                extracted_images = []
                if file_ext == '.pdf':
                    # PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
                    extracted_images = extract_images_from_pdf(file_path)
                    print(f"    ğŸ–¼ï¸ PDFì—ì„œ {len(extracted_images)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œë¨")
                    
                    loader = PyPDFLoader(file_path)
                    docs = loader.load()
                    
                elif file_ext == '.txt':
                    loader = TextLoader(file_path, encoding='utf-8')
                    docs = loader.load()
                    
                elif file_ext in ['.docx', '.doc']:
                    loader = Docx2txtLoader(file_path)
                    docs = loader.load()
                    
                elif file_ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                    # ì´ë¯¸ì§€ëŠ” OCRì„ í†µí•´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    try:
                        loader = UnstructuredImageLoader(file_path)
                        docs = loader.load()
                    except Exception as e:
                        print(f"    âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ({file_name}): {e}")
                        # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ì‹œ íŒŒì¼ëª…ê³¼ ê²½ë¡œë§Œ ì €ì¥
                        docs = [Document(
                            page_content=f"ì´ë¯¸ì§€ íŒŒì¼: {file_name}",
                            metadata={"source": file_path, "type": "image"}
                        )]
                else:
                    print(f"    âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
                    continue
                
                # ë©”íƒ€ë°ì´í„°ì— íŒŒì¼ëª… ì¶”ê°€
                for doc in docs:
                    if "source" not in doc.metadata:
                        doc.metadata["source"] = file_path
                    doc.metadata["filename"] = file_name
                    
                    # PDF íŒŒì¼ì˜ ê²½ìš° ì¶”ì¶œëœ ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€
                    if file_ext == '.pdf':
                        doc.metadata["extracted_images"] = extracted_images
                        doc.metadata["has_images"] = len(extracted_images) > 0
                
                self.documents.extend(docs)
                print(f"    âœ… {len(docs)}ê°œ ë¬¸ì„œ/í˜ì´ì§€ ë¡œë“œë¨")
                
            except Exception as e:
                print(f"    âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_name}): {e}")
                continue

    def _setup_db(self):
        """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
        DB_CONFIG = {
            'host': os.getenv("DB_HOST"),
            'port': 5432,
            'dbname': os.getenv('DB_NAME'),
            'user': os.getenv('DB_USER'),
            'password': os.getenv('DB_PASS'),
        }

        try:
            conn = psycopg.connect(**DB_CONFIG)
            cur = conn.cursor()
            cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
            conn.commit()
            cur.close()
            conn.close()
        except Exception as e:
            raise RuntimeError(f"Postgres ì—°ê²° ì‹¤íŒ¨: {e}")

        return (
            f"postgresql+psycopg://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
            f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}"
        )

    def _create_chain(self):
        """RAG ì²´ì¸ ìƒì„±"""
        def format_docs(docs):
            formatted = []
            for idx, doc in enumerate(docs, 1):
                source = doc.metadata.get('filename', doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ'))
                
                # ë¬¸ì„œ ë‚´ìš©
                content = f"[ì¶œì²˜: {source}]\n{doc.page_content}"
                
                # PDFì—ì„œ ì¶”ì¶œëœ ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€
                if doc.metadata.get('has_images', False):
                    extracted_images = doc.metadata.get('extracted_images', [])
                    if extracted_images:
                        image_info = f"\n[í¬í•¨ëœ ì´ë¯¸ì§€: {len(extracted_images)}ê°œ]"
                        image_list = "\n" + "\n".join([f"- ì´ë¯¸ì§€ íŒŒì¼: {os.path.basename(img_path)}" for img_path in extracted_images])
                        content += image_info + image_list
                
                formatted.append(content)
            return "\n\n---\n\n".join(formatted)

        return (
            {
                "context": self.retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | self.prompt
            | self.llm
            | StrOutputParser()
        )

    def ask(self, question: str) -> str:
        """RAG ì§ˆì˜ ì‹¤í–‰"""
        try:
            return self.rag_chain.invoke(question)
        except Exception as e:
            return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}"
    
    def get_loaded_files_info(self) -> dict:
        """ë¡œë“œëœ íŒŒì¼ ì •ë³´ ë°˜í™˜"""
        return {
            "total_files": len(self.file_paths),
            "total_documents": len(self.documents),
            "total_chunks": len(self.splits),
            "files": [Path(fp).name for fp in self.file_paths]
        }