{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d02ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015354075469076633\n",
      "데이터 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import sys\n",
    "import psycopg2  \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()  \n",
    "STUDENT_NO = '47'\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# PostgresSQL 접속정보\n",
    "\n",
    "DB_CONFIG = {\n",
    "  'host': os.getenv(\"HOST\"),\n",
    "  'port': 5432,\n",
    "  'database': 'postgres',\n",
    "  'user' : 'postgres',\n",
    "  'password' : os.getenv(\"PASSWORD\")\n",
    "}\n",
    "\n",
    "# 임베딩 함수\n",
    "def get_embedding(text: str, model: str = \"text-embedding-3-small\") -> list:\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    print(response.data[0].embedding[0])\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# DB에 저장\n",
    "def save_to_postgres(text: str, vector: list):   \n",
    "    conn = psycopg2.connect(**DB_CONFIG) \n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        sql = \"\"\"\n",
    "          INSERT INTO test_vector (student_no, name, embedding)\n",
    "          VALUES (%s, %s, %s)\n",
    "        \"\"\"\n",
    "        cur.execute(sql, (STUDENT_NO, text, vector))\n",
    "        conn.commit()\n",
    "        print(\"데이터 저장 완료!\")\n",
    "    except Exception as e:\n",
    "        print(\"DB 오류:\", e)\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "# 메인 실행\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = input(\"임베딩할 문장을 입력하세요: \")\n",
    "    embedding_vector = get_embedding(input_text)\n",
    "    save_to_postgres(input_text, embedding_vector)\n",
    "    # print(\"--------------\")\n",
    "    # print(len(embedding_vector))\n",
    "    # print(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7af2c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 가장 유사한 문장: 남산위에 저소나무 철갑을 두른듯 \n",
      "거리 (낮을수록 유사): 1.163503\n"
     ]
    }
   ],
   "source": [
    "# python과 openAI를 이용한 벡터 검색\n",
    "\n",
    "import openai\n",
    "import psycopg2  #  **“Python + C + PostgreSQL version 2”**라는 의미라고 보시면 됩니다.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "\n",
    "load_dotenv()  \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# PostgresSQL 접속정보\n",
    "\n",
    "DB_CONFIG = {\n",
    "  'host': os.getenv(\"HOST\"),\n",
    "  'port': 5432,\n",
    "  'database': 'postgres',\n",
    "  'user' : 'postgres',\n",
    "  'password' : os.getenv(\"PASSWORD\")\n",
    "}\n",
    "\n",
    "# 임베딩 함수\n",
    "def get_embedding(text: str, model: str = \"text-embedding-3-small\") -> list:\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "# 가장 유사한 row 함수 검색\n",
    "def find_most_similar(text: str) :\n",
    "  #임베딩 벡터 생성\n",
    "  vector = get_embedding(text)\n",
    "  \n",
    "  #DB 연결\n",
    "  conn = psycopg2.connect(**DB_CONFIG) \n",
    "  register_vector(conn)\n",
    "  cur = conn.cursor()\n",
    "  try:\n",
    "      sql = \"\"\"\n",
    "        SELECT name,embedding <-> %s::vector AS distance FROM test_vector \n",
    "        ORDER BY distance ASC LIMIT 1;\n",
    "      \"\"\"\n",
    "      cur.execute(sql, (vector,)) ## 튜플로 넘겨야 함 (vector) 는 튜플이 아님\n",
    "      result = cur.fetchone()\n",
    "      \n",
    "      if result:\n",
    "        matched_text, similarity = result\n",
    "        print(f\"\\n 가장 유사한 문장: {matched_text} \")\n",
    "        print(f\"거리 (낮을수록 유사): {similarity:.6f}\")\n",
    "      else :\n",
    "        print(\"X 유사한 문장을 찾을 수 없습니다.\")\n",
    "      \n",
    "  except Exception as e:\n",
    "      print(\"DB 오류:\", e)\n",
    "\n",
    "  finally:\n",
    "      cur.close()\n",
    "      conn.close()\n",
    "  \n",
    "  \n",
    "# 메인 실행\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"유사한 문장을 찾을 문장을 입력하세요: \")\n",
    "    find_most_similar(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56047437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI API 호출, MODEL=gemini-2.0-flash-lite\n",
      "This appears to be the path to a Jupyter kernel configuration file. Let's break down what each part likely means:\n",
      "\n",
      "*   **`--f=`**: This is likely a command-line argument flag. The \"f\" probably stands for \"file\". It indicates that a filename will follow.\n",
      "\n",
      "*   **`/Users/hyunjunson/Library/Jupyter/runtime/`**: This is the directory path where the kernel configuration file is located.\n",
      "    *   `/Users/hyunjunson/`: This is the user's home directory, specific to the user named \"hyunjunson\" on a macOS system.\n",
      "    *   `/Library/Jupyter/`: This is a standard location where Jupyter stores its configuration and runtime data.\n",
      "    *   `/runtime/`: This subdirectory often contains temporary or dynamic files related to running Jupyter kernels.\n",
      "\n",
      "*   **`kernel-v3a3fdcb66999f394feea5ed066e9fd458585a83bf.json`**: This is the filename of the kernel configuration file.\n",
      "    *   `kernel-`: This prefix suggests that the file is related to a Jupyter kernel.\n",
      "    *   `v3a3fdcb66999f394feea5ed066e9fd458585a83bf`: This is likely a unique identifier (a UUID or similar) generated when the kernel was started.  This helps Jupyter manage multiple kernels.\n",
      "    *   `.json`: This indicates that the file is in JSON (JavaScript Object Notation) format.  JSON is a common format for storing structured data.  The file will contain information about the Jupyter kernel, such as:\n",
      "        *   The kernel's connection information (ports, IP address).\n",
      "        *   The kernel's Python environment.\n",
      "        *   Other settings specific to the kernel.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "The command-line argument `--f=/Users/hyunjunson/Library/Jupyter/runtime/kernel-v3a3fdcb66999f394feea5ed066e9fd458585a83bf.json` tells a program (likely Jupyter itself or a related utility) to read the kernel configuration from the specified JSON file.  This is how Jupyter knows how to connect to and communicate with a running kernel to execute code in a notebook.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI \n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/openai\"\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "LLM_ID = \"gemini-2.0-flash-lite\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=GEMINI_API_URL,\n",
    "    api_key=GEMINI_API_KEY\n",
    ")\n",
    "\n",
    "def ai_chat(messages: list):\n",
    "    # openai api package를 통해 gemini api를 호출합니다.\n",
    "    print(f\"GEMINI API 호출, MODEL={LLM_ID}\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=LLM_ID,\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    messages = []\n",
    "    if len(sys.argv) < 2:   \n",
    "        print(f\"Usage: {sys.argv[0]} '질문내용'\")\n",
    "        sys.exit()\n",
    "    \n",
    "    # 명령줄 인자 전체를 합쳐서 질문으로 사용\n",
    "    question = ' '.join(sys.argv[1:])\n",
    "    messages.append({'role': 'user', 'content': question})\n",
    "    \n",
    "    response = ai_chat(messages=messages)\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9232af84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjunson/Project/green-hat/backend/ml-pipline/yes/envs/langCh-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5013\n",
      " * Running on http://192.168.0.99:5013\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [30/Sep/2025 15:05:58] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 15:06:07] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 15:06:08] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def hello() :\n",
    "    return render_template('hello.html')\n",
    "\n",
    "@app.route('/greeting')\n",
    "def hello2() :\n",
    "    return render_template('greeting.html')\n",
    "  \n",
    "if __name__ == \"__main__\" :\n",
    "  app.run(host=\"0.0.0.0\", port=5013)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559007d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5013\n",
      " * Running on http://192.168.0.99:5013\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [30/Sep/2025 16:26:40] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:26:41] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:26:42] \"GET /?page=2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:26:44] \"GET /?page=3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:26:46] \"GET /?page=2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:26:47] \"GET /?page=1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:33:50] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:33:52] \"GET /?page=2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:33:53] \"GET /?page=3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:33:55] \"GET /?page=2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Sep/2025 16:33:56] \"GET /?page=1 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from flask import Flask, render_template, request, g\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# DB 연결정보\n",
    "db_config = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"dbname\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASS\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\")\n",
    "}\n",
    "\n",
    "def get_db():\n",
    "    if 'db' not in g:\n",
    "        g.db = psycopg2.connect(**db_config)\n",
    "    return g.db\n",
    "\n",
    "@app.teardown_appcontext\n",
    "def close_db(error):\n",
    "    db = g.pop('db', None)\n",
    "    if db is not None:\n",
    "        db.close()\n",
    "\n",
    "# main page route\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    # test_vector 테이블의 데이터를 페이지네이션 해서 표시\n",
    "    page = request.args.get('page', 1, type=int)\n",
    "    per_page = 10\n",
    "\n",
    "    try:\n",
    "        conn = get_db()\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # 전체 항목 수 계산\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM test_vector;\")\n",
    "        total_items = cursor.fetchone()[0]\n",
    "        total_pages = (total_items + per_page - 1) // per_page\n",
    "\n",
    "        # 현재 페이지 데이터 조회 (offset, limit)\n",
    "        offset = (page - 1) * per_page\n",
    "        query = \"\"\"\n",
    "            SELECT id, student_no, name\n",
    "            FROM test_vector\n",
    "            ORDER BY id DESC\n",
    "            LIMIT %s OFFSET %s;\n",
    "        \"\"\"\n",
    "        cursor.execute(query, (per_page, offset))\n",
    "        documents = cursor.fetchall()\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        documents = []\n",
    "        total_pages = 0\n",
    "\n",
    "    finally:\n",
    "        if 'cursor' in locals():\n",
    "            cursor.close()\n",
    "\n",
    "    return render_template(\n",
    "        \"index.html\",\n",
    "        documents=documents,\n",
    "        page=page,\n",
    "        total_pages=total_pages\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5013)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langCh-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
