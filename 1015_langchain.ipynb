{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d361838",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e82b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랭체인(LangChain)은 자연어 처리(NLP) 및 인공지능(AI) 애플리케이션을 개발하기 위한 프레임워크입니다. 주로 대화형 AI, 챗봇, 언어 모델을 구축하는 데 사용됩니다. 이 프레임워크는 다양한 도구와 기술을 통합하여 개발자들이 손쉽게 언어 모델을 활용하고, 이를 기반으로 여러 기능을 구현할 수 있도록 돕습니다.\n",
      "\n",
      "랭체인의 주요 특징은 다음과 같습니다:\n",
      "\n",
      "1. **모듈화**: 다양한 기능과 컴포넌트를 모듈화하여 개발자들이 필요에 따라 선택하고 조합할 수 있습니다.\n",
      "  \n",
      "2. **데이터 연결**: 외부 데이터 소스와의 연결을 지원하여 언어 모델이 특정 도메인이나 주제에 맞춘 정보에 접근할 수 있게 합니다.\n",
      "\n",
      "3. **상태 관리**: 대화의 상태를 추적하고 관리할 수 있는 기능을 제공하여 보다 자연스러운 대화 흐름을 구현할 수 있습니다.\n",
      "\n",
      "4. **사용자 정의**: 개발자가 자신의 요구에 맞게 언어 모델을 커스터마이즈 할 수 있도록 다양한 옵션을 제공합니다.\n",
      "\n",
      "5. **통합성**: 여러 외부 API나 시스템과의 통합이 용이하여, 실제 애플리케이션에서 활용하기 쉽습니다.\n",
      "\n",
      "랭체인은 주로 파이썬으로 개발되며, 자연어 이해(NLU), 질문 응답 시스템, 요약 생성 등 다양한 언어 기반 애플리케이션을 만드는 데 유용하게 사용됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해줘\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "question = {\"topic\" : \"랭체인\"}\n",
    "\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f31734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf를 총29개의 페이지로 불러왔습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. pdf 문서 로드\n",
    "\n",
    "loader = PyMuPDFLoader(file_path=\"data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\")\n",
    "pages = loader.load()\n",
    "print(f\"pdf를 총{len(pages)}개의 페이지로 불러왔습니다.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca611bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텍스트의 총 토큰 수 : 18\n",
      "\n",
      "TokenTextSplitter 결과 (총 2개)\n",
      "[1] (토큰: 15 This splitter is essential for managing LLM context windows and optimizing API costs by)\n",
      "[2] (토큰: 8  and optimizing API costs by counting tokens.)\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "encoding = tiktoken.get_encoding('o200k_base') # <Encoding 'o200k_base'>\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int :\n",
    "  \"\"\" 문자열의 토큰 수를 계산하여 반환\"\"\"\n",
    "  return len(encoding.encode(string))\n",
    "\n",
    "sample_text = \"This splitter is essential for managing LLM context windows and optimizing API costs by counting tokens.\"\n",
    "\n",
    "total_tokens = num_tokens_from_string(sample_text)\n",
    "print(f\"원본 텍스트의 총 토큰 수 : {total_tokens}\\n\")\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "  chunk_size = 15,\n",
    "  chunk_overlap = 5,\n",
    "  encoding_name = \"o200k_base\"\n",
    ")\n",
    "  \n",
    "#2. 텍스트 분할\n",
    "chunks = text_splitter.split_text(sample_text)\n",
    "\n",
    "# 3. 결과확인\n",
    "\n",
    "print(f\"TokenTextSplitter 결과 (총 {len(chunks)}개)\")\n",
    "for i, chunk in enumerate(chunks) :\n",
    "  chunk_tokens = num_tokens_from_string(chunk)\n",
    "  print(f\"[{i+1}] (토큰: {chunk_tokens} {chunk})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5165962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# pdf 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "file_path = \"data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"---- PDF 문서 로드 완료 ---\")\n",
    "print(f\"총 {len(documents)}개의 페이지가 로드 되었습니다.\\n\")\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model= \"text-embedding-3-small\")\n",
    "\n",
    "# 문서 내용만 추출\n",
    "documents_texts = [doc.page_content for doc in documents]\n",
    "\n",
    "document_embeddings = embedding_model.embed_documents(documents_texts)\n",
    "\n",
    "print(\"----- 여러 문서 임베딩( embed_documents) 결과 ---\")\n",
    "print(f\"총 {len(document_embeddings)}개의 페이지가 임베딩 되었습니다.\")\n",
    "print(f\"첫 번째 페이지의 벡터 차원(크기): {len(document_embeddings[0])}\")\n",
    "print(f\"첫 번째 페이지의 벡터 차원(앞 5개 값): {document_embeddings[0][:5]}\\n\")\n",
    "\n",
    "# 첫번째 페이지 내용 미리보기\n",
    "print(\"----- 여러 문서 임베딩( embed_documents) 결과 ---\")\n",
    "print(\"document_texts[0][:500]\")\n",
    "print(\"...\\n\")\n",
    "\n",
    "# 단일 텍스트 질의 임베딩\n",
    "\n",
    "query = \"AI 산업 동향에 대해 알려주세요\"\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "print(\"----- 단일 질의 임베딩 (embed_query) 결과 ---\")\n",
    "print(f\"총 {len(document_embeddings)}개의 페이지가 임베딩 되었습니다.\")\n",
    "print(f\"첫 번째 페이지의 벡터 차원(앞 5개 값): {document_embeddings[0][:5]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6623fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import HuggingFaceEmbeddings\n",
    "\n",
    "# pdf 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "file_path = \"data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"---- PDF 문서 로드 완료 ---\")\n",
    "print(f\"총 {len(documents)}개의 페이지가 로드 되었습니다.\\n\")\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "  model_name = \n",
    ")\n",
    "\n",
    "# 문서 내용만 추출\n",
    "documents_texts = [doc.page_content for doc in documents]\n",
    "\n",
    "document_embeddings = embedding_model.embed_documents(documents_texts)\n",
    "\n",
    "print(\"----- 여러 문서 임베딩( embed_documents) 결과 ---\")\n",
    "print(f\"총 {len(document_embeddings)}개의 페이지가 임베딩 되었습니다.\")\n",
    "print(f\"첫 번째 페이지의 벡터 차원(크기): {len(document_embeddings[0])}\")\n",
    "print(f\"첫 번째 페이지의 벡터 차원(앞 5개 값): {document_embeddings[0][:5]}\\n\")\n",
    "\n",
    "# 첫번째 페이지 내용 미리보기\n",
    "print(\"----- 여러 문서 임베딩( embed_documents) 결과 ---\")\n",
    "print(\"document_texts[0][:500]\")\n",
    "print(\"...\\n\")\n",
    "\n",
    "# 단일 텍스트 질의 임베딩\n",
    "\n",
    "query = \"AI 산업 동향에 대해 알려주세요\"\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "print(\"----- 단일 질의 임베딩 (embed_query) 결과 ---\")\n",
    "print(f\"총 {len(document_embeddings)}개의 페이지가 임베딩 되었습니다.\")\n",
    "print(f\"첫 번째 페이지의 벡터 차원(앞 5개 값): {document_embeddings[0][:5]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cff80d",
   "metadata": {},
   "source": [
    "## 벡터스토어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0dd59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Extension 생성 중 에러 발생: invalid connection option \"database\"\n",
      "\n",
      "PDF 파일을 총 29 페이지로 불러왔습니다.\n",
      "문서를 총 70개의 청크로 분할했습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collection not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ vector-db-test 컬렉션에 문서를 추가 완료했습니다.\n",
      "\n",
      "--- 검색 결과 ---\n",
      "\n",
      "[결과 1]\n",
      "내용: 정책･법제기업･산업기술･연구인력･교육\n",
      "19\n",
      "MBZUAI와 G42, 추론 AI 모델 ‘K2 Think’ 오픈소스 공개nUAE의 모하메드 빈 자이드 AI 대학(MBZUAI)과 국영 AI 기업 G42가 혁신적인 사후 학습 기법과 테스트-타임 스케일링을 적용한 매개변수 320억 개의 추론 AI 모델 ‘K2 Think’를 공개nK2 Think는 수학 벤치마크에서 딥...\n",
      "출처: data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\n",
      "페이지: 20\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[결과 2]\n",
      "내용: 2025년10월호인공지능 산업의 최신 동향...\n",
      "출처: data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\n",
      "페이지: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[결과 3]\n",
      "내용: £과학기술, 산업, 소비, 민생, 거버넌스 역량, 국제협력의 6대 영역에서 AI 플러스 추진n중국 국무원이 AI와 경제·사회의 심층 융합을 목표로 ‘AI 플러스(AI+) 행동 심화 추진에 관한 의견’을 발표∙2027년까지 폭넓고 심도 있는 AI 융합의 실현 및 차세대 지능형 단말과 지능형 에이전트 등의 보급률 70% 돌파, 2030년까지는 차세대 지능형 단...\n",
      "출처: data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\n",
      "페이지: 3\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv(\"DB_HOST\"),\n",
    "    'port': 5432,\n",
    "    'database': os.getenv('DB_NAME'), \n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASS'),\n",
    "}\n",
    "\n",
    "COLLECTION_NAME = \"vector-db-test\"\n",
    "FILE_PATH = \"data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\"\n",
    "\n",
    "# psycopg를 사용하여 vector extension 설치\n",
    "conn = None\n",
    "\n",
    "try:\n",
    "    conn = psycopg.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")  \n",
    "    conn.commit()\n",
    "    print(\"✅ vector extension을 성공적으로 확인/생성했습니다.\")\n",
    "    cursor.close()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Extension 생성 중 에러 발생: {e}\")\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "\n",
    "# PDF 로드 및 텍스트 분할\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "pages = loader.load()\n",
    "print(f\"PDF 파일을 총 {len(pages)} 페이지로 불러왔습니다.\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "documents_to_add = text_splitter.split_documents(pages)\n",
    "print(f\"문서를 총 {len(documents_to_add)}개의 청크로 분할했습니다.\")\n",
    "\n",
    "# 랭체인 pgvector 준비\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(driver=\"psycopg\", **DB_CONFIG) \n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    collection_name=\"ensemble_example\",\n",
    "    connection=CONNECTION_STRING,   \n",
    "    pre_delete_collection=True\n",
    ")\n",
    "\n",
    "print(f\"✅ {COLLECTION_NAME} 컬렉션에 문서를 추가 완료했습니다.\")\n",
    "\n",
    "# 유사도 검색\n",
    "retrieved_docs = db.similarity_search(\"생성형 AI의 기술 동향에 대해 알려줘\", k=3)\n",
    "print(\"\\n--- 검색 결과 ---\")\n",
    "\n",
    "if retrieved_docs:\n",
    "    for idx, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"\\n[결과 {idx}]\")\n",
    "        print(f\"내용: {doc.page_content[:200]}...\")  \n",
    "        print(f\"출처: {doc.metadata.get('source', '알 수 없음')}\")\n",
    "        print(f\"페이지: {doc.metadata.get('page', '알 수 없음')}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Extension 생성 중 에러 발생: invalid connection option \"database\"\n",
      "\n",
      "================================================================================\n",
      "Ensemble Retriever (Hybrid Search)\n",
      "- Sparse(BM25) + Dense(Vector) 결합\n",
      "- 키워드와 의미 모두 고려\n",
      "================================================================================\n",
      "\n",
      "[결과 1]\n",
      "내용: 2025년10월호인공지능 산업의 최신 동향...\n",
      "출처: data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\n",
      "페이지: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[결과 2]\n",
      "내용: 보안 취약점을 줄이기 위한 안전 규정 수립과 이행, 공급망 보안 강화, AI 모델 안전 가드레일 구축 등을 진행∙(파생 위험 대책) 친환경 AI 모델 및 컴퓨팅 기술, 기술 표준 개발을 모색하고 생명과 건강에 영향을 미치는 핵심 분야의 AI 시스템에 대한 비상 통제 대책을 마련 n(종합 거버넌스 조치) 기술적 대책 마련과 함께 정부, 사회단체, 사용자 등 ...\n",
      "출처: data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\n",
      "페이지: 7\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[결과 3]\n",
      "내용: 정책･법제기업･산업기술･연구인력･교육\n",
      "19\n",
      "MBZUAI와 G42, 추론 AI 모델 ‘K2 Think’ 오픈소스 공개nUAE의 모하메드 빈 자이드 AI 대학(MBZUAI)과 국영 AI 기업 G42가 혁신적인 사후 학습 기법과 테스트-타임 스케일링을 적용한 매개변수 320억 개의 추론 AI 모델 ‘K2 Think’를 공개nK2 Think는 수학 벤치마크에서 딥...\n",
      "출처: data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\n",
      "페이지: 20\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[결과 4]\n",
      "내용: 정책･법제기업･산업기술･연구인력･교육\n",
      "3\n",
      "대만 행정원, AI 기본법 통과 후 입법원에 제출n대만 행정원이 AI 개발과 응용에 우호적 환경을 조성해 대만을 글로벌 AI 개발의 핵심 거점으로 만들기 위한 「AI 기본법」을 가결하고 입법원에 제출n법안은 AI 개발과 응용의 기본 원칙과 정부의 역할과 의무, AI 위험관리 방안을 포괄하며, 기술 혁신과 국제협력에 ...\n",
      "출처: data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\n",
      "페이지: 4\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[결과 5]\n",
      "내용: £과학기술, 산업, 소비, 민생, 거버넌스 역량, 국제협력의 6대 영역에서 AI 플러스 추진n중국 국무원이 AI와 경제·사회의 심층 융합을 목표로 ‘AI 플러스(AI+) 행동 심화 추진에 관한 의견’을 발표∙2027년까지 폭넓고 심도 있는 AI 융합의 실현 및 차세대 지능형 단말과 지능형 에이전트 등의 보급률 70% 돌파, 2030년까지는 차세대 지능형 단...\n",
      "출처: data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\n",
      "페이지: 3\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv(\"DB_HOST\"),\n",
    "    'port': 5432,\n",
    "    'database': os.getenv('DB_NAME'),  \n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASS'),\n",
    "}\n",
    "\n",
    "COLLECTION_NAME = \"vector-db-test\"\n",
    "FILE_PATH = \"data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\"\n",
    "\n",
    "# psycopg를 사용하여 vector extension 설치\n",
    "conn = None\n",
    "\n",
    "try:\n",
    "    conn = psycopg.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    conn.commit()\n",
    "    print(\"✅ vector extension을 성공적으로 확인/생성했습니다.\")\n",
    "    cursor.close()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Extension 생성 중 에러 발생: {e}\")\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "\n",
    "# PDF 로드 및 텍스트 분할\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "pages = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(pages)\n",
    "\n",
    "# Vector store 생성\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(driver=\"psycopg\", **DB_CONFIG)\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = PGVector.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    collection_name=\"ensemble_example\",\n",
    "    connection=CONNECTION_STRING,   \n",
    "    pre_delete_collection=True\n",
    ")\n",
    "\n",
    "# Vector retriever 생성\n",
    "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# BM25 retriever 생성\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Ensemble Retriever (Hybrid Search)\")\n",
    "print(\"- Sparse(BM25) + Dense(Vector) 결합\")\n",
    "print(\"- 키워드와 의미 모두 고려\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Ensemble Retriever 생성\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# 검색 실행 (invoke 오타 수정)\n",
    "results = ensemble_retriever.invoke(\"생성형 AI 기술 동향\")\n",
    "\n",
    "# 결과 출력\n",
    "if results:\n",
    "    for idx, doc in enumerate(results, 1):\n",
    "        print(f\"\\n[결과 {idx}]\")\n",
    "        print(f\"내용: {doc.page_content[:200]}...\")\n",
    "        print(f\"출처: {doc.metadata.get('source', '알 수 없음')}\")\n",
    "        print(f\"페이지: {doc.metadata.get('page', '알 수 없음')}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d743a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1단계] 문서로드 (Document Loader)\n",
      "--------------------------------------------------------------------------------\n",
      "총 29 페이지 로드 완료\n",
      "\n",
      "[2단계] 문서 분할 (Text Splitter)\n",
      "--------------------------------------------------------------------------------\n",
      "총 70개의 청크로 분할 완료\n",
      "첫 번째 청크: 2025년10월호인공지능 산업의 최신 동향...\n",
      "\n",
      "[3단계] 문서 임베딩 (Document Embedding)\n",
      "--------------------------------------------------------------------------------\n",
      "임베딩 모델 준비 완료\n",
      "벡터 차원: 1536차원\n",
      "샘플 벡터(처음 5개): [0.04349127784371376, 0.0312628448009491, 0.02276095747947693, 0.0059245433658361435, 0.0064712525345385075]\n",
      "\n",
      "[4단계] Postgres 벡터 확장 확인\n",
      "--------------------------------------------------------------------------------\n",
      "✅ vector extension을 성공적으로 확인/생성했습니다.\n",
      "\n",
      "[5단계] PGVector 저장 (Vector Store)\n",
      "--------------------------------------------------------------------------------\n",
      "✅ 벡터스토어에 70개 청크 저장 완료\n",
      "컬렉션 이름: rag_example\n",
      "\n",
      "[6단계] 검색기(Retriever)\n",
      "--------------------------------------------------------------------------------\n",
      "검색기 생성 완료\n",
      "테스트 쿼리: 생성형 AI의 최신 기술 동향은?\n",
      "검색된 문서 수: 3\n",
      "첫 번째 결과: 2025년10월호인공지능 산업의 최신 동향...\n",
      "\n",
      "[7단계] 프롬프트(Prompt)\n",
      "--------------------------------------------------------------------------------\n",
      "프롬프트 템플릿 생성 완료\n",
      "시스템 역할: AI 기술 전문가\n",
      "프롬프트 구조: 문맥(context) + 질문(question)\n",
      "\n",
      "[8단계] LLM(Large Language Model)\n",
      "--------------------------------------------------------------------------------\n",
      "LLM 모델 준비 완료\n",
      "모델: gpt-4o-mini\n",
      "\n",
      "[9단계] RAG 체인 구성\n",
      "--------------------------------------------------------------------------------\n",
      "RAG 체인 구성 완료 ✅\n",
      "RAG 시스템 실행 테스트\n",
      "================================================================================\n",
      "\n",
      "[질문 1] 중국 국무원이 발표한 'AI플러스' 정책의 3단계 중장기 목표는 무엇이며, 6대 핵심 영역은 어디인가요?\n",
      "--------------------------------------------------------------------------------\n",
      "답변:\n",
      "중국 국무원이 발표한 'AI플러스' 정책의 3단계 중장기 목표는 2035년까지 전면적인 지능형 경제사회로 이행하는 것입니다. \n",
      "\n",
      "6대 핵심 영역은 다음과 같습니다:\n",
      "1. 과학기술\n",
      "2. 산업 발전\n",
      "3. 소비 품질 향상\n",
      "4. 민생\n",
      "5. 거버넌스 역량\n",
      "6. 국제협력\n",
      "\n",
      "이 정보는 문서 1과 문서 2에서 확인할 수 있습니다.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[질문 2] 구글이 공개한 이미지 편집 모델 '제미나이 2.5 플래시 이미지'의 가장 큰 특징은 무엇인가요?\n",
      "--------------------------------------------------------------------------------\n",
      "답변:\n",
      "구글이 공개한 이미지 편집 모델 '제미나이 2.5 플래시 이미지'의 가장 큰 특징은 캐릭터 일관성 유지에서 뛰어난 품질을 발휘한다는 점입니다. 이 모델은 사람이나 동물과 같은 캐릭터의 형태를 유지하면서 배경이나 설정을 바꾸거나 여러 장의 사진을 합성할 수 있도록 지원합니다. 또한, 사용자가 업로드한 이미지의 특정 부분을 수정하면서 나머지 부분을 유지하는 기능도 제공하며, 한 이미지의 스타일을 다른 이미지에 적용하는 기능도 지원합니다. (참고: 문서 1에서 \"캐릭터 일관성 유지에서 뛰어난 품질을 달성\" 및 \"여러 장의 사진을 업로드하고 합성하여 새로운 장면을 만들어낼 수 있도록 지원\" 부분)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[질문 3] 스탠포드 대학의 연구결과, 생성 AI의 확산이 경력 초기 근로자의 고용에 어떤 영향을 미치고 있나요?\n",
      "--------------------------------------------------------------------------------\n",
      "답변:\n",
      "스탠포드 대학의 연구 결과에 따르면, 생성 AI의 확산이 경력 초기 근로자들에게 불균형적으로 부정적인 고용 효과를 유발하고 있으며, AI 노출도가 높은 직업에서 경력 초기 근로자의 고용이 뚜렷하게 감소하고 있다고 합니다. 이러한 결과는 경기 상황 요인을 배제하거나 대안적 표본 구성을 사용했을 때도 일관되게 나타났습니다. (문서 1 및 문서 2 참고)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough  \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"\\n[1단계] 문서로드 (Document Loader)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "FILE_PATH = \"data/SPRi AI Brief_10월호_산업동향_1002_F.pdf\"\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"총 {len(documents)} 페이지 로드 완료\")\n",
    "\n",
    "print(\"\\n[2단계] 문서 분할 (Text Splitter)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"총 {len(splits)}개의 청크로 분할 완료\")\n",
    "print(f\"첫 번째 청크: {splits[0].page_content[:150]}...\")\n",
    "\n",
    "print(\"\\n[3단계] 문서 임베딩 (Document Embedding)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "sample_text = \"생성형 AI 기술동향\"\n",
    "sample_vector = embeddings_model.embed_query(sample_text)\n",
    "\n",
    "print(\"임베딩 모델 준비 완료\")\n",
    "print(f\"벡터 차원: {len(sample_vector)}차원\")\n",
    "print(f\"샘플 벡터(처음 5개): {sample_vector[:5]}\")\n",
    "\n",
    "print(\"\\n[4단계] Postgres 벡터 확장 확인\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv(\"DB_HOST\"),\n",
    "    'port': 5432,\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASS'),\n",
    "}\n",
    "\n",
    "conn = None\n",
    "\n",
    "try:\n",
    "    conn = psycopg.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    conn.commit()\n",
    "    print(\"✅ vector extension을 성공적으로 확인/생성했습니다.\")\n",
    "    cursor.close()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Extension 생성 중 에러 발생: {e}\")\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "\n",
    "print(\"\\n[5단계] PGVector 저장 (Vector Store)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "CONNECTION_STRING = (\n",
    "    f\"postgresql+psycopg://{DB_CONFIG['user']}:{DB_CONFIG['password']}@\"\n",
    "    f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}\"\n",
    ")\n",
    "\n",
    "vectorstore = PGVector.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings_model,\n",
    "    collection_name=\"rag_example\",\n",
    "    connection=CONNECTION_STRING,\n",
    "    pre_delete_collection=True\n",
    ")\n",
    "\n",
    "print(f\"✅ 벡터스토어에 {len(splits)}개 청크 저장 완료\")\n",
    "print(\"컬렉션 이름: rag_example\")\n",
    "\n",
    "print(\"\\n[6단계] 검색기(Retriever)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "test_query = \"생성형 AI의 최신 기술 동향은?\"\n",
    "retrieved_docs = retriever.invoke(test_query)\n",
    "\n",
    "print(\"검색기 생성 완료\")\n",
    "print(f\"테스트 쿼리: {test_query}\")\n",
    "print(f\"검색된 문서 수: {len(retrieved_docs)}\")\n",
    "print(f\"첫 번째 결과: {retrieved_docs[0].page_content[:100]}...\")\n",
    "\n",
    "print(\"\\n[7단계] 프롬프트(Prompt)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"당신은 AI 기술 전문가입니다.\n",
    "아래 제공된 문맥(Context)을 반드시 참고하여 질문에 답변하세요.\n",
    "\n",
    "중요:\n",
    "1. 문맥에 관련 내용이 있으면 그것을 바탕으로 답변하세요.\n",
    "2. 문맥에 없는 내용만 \"제공된 문서에서 해당 정보를 찾을 수 없습니다.\"라고 답변하세요.\n",
    "3. 답변 시 문맥의 어느 부분을 참고했는지 명시하세요.\n",
    "\n",
    "문맥:\n",
    "{context}\n",
    "\"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "print(\"프롬프트 템플릿 생성 완료\")\n",
    "print(\"시스템 역할: AI 기술 전문가\")\n",
    "print(\"프롬프트 구조: 문맥(context) + 질문(question)\")\n",
    "\n",
    "print(\"\\n[8단계] LLM(Large Language Model)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.5)\n",
    "\n",
    "print(\"LLM 모델 준비 완료\")\n",
    "print(\"모델: gpt-4o-mini\")\n",
    "\n",
    "print(\"\\n[9단계] RAG 체인 구성\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted = []\n",
    "    for idx, doc in enumerate(docs, 1):\n",
    "        formatted.append(f\"[문서 {idx}]\\n{doc.page_content}\")\n",
    "    return \"\\n\\n---\\n\\n\".join(formatted)\n",
    "\n",
    "# ✅ 체인 구성\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG 체인 구성 완료 ✅\")\n",
    "\n",
    "\n",
    "# RAG 실행 테스트\n",
    "print(\"RAG 시스템 실행 테스트\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 질문 목록\n",
    "question_list = [\n",
    "    \"중국 국무원이 발표한 'AI플러스' 정책의 3단계 중장기 목표는 무엇이며, 6대 핵심 영역은 어디인가요?\",\n",
    "    \"구글이 공개한 이미지 편집 모델 '제미나이 2.5 플래시 이미지'의 가장 큰 특징은 무엇인가요?\",\n",
    "    \"스탠포드 대학의 연구결과, 생성 AI의 확산이 경력 초기 근로자의 고용에 어떤 영향을 미치고 있나요?\"\n",
    "]\n",
    "\n",
    "for idx, question in enumerate(question_list, 1):\n",
    "    print(f\"\\n[질문 {idx}] {question}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # RAG chain 실행\n",
    "    answer = rag_chain.invoke(question)\n",
    "    \n",
    "    print(f\"답변:\\n{answer}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (oracle-langchain)",
   "language": "python",
   "name": "oracle-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
