{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2716cf",
   "metadata": {},
   "source": [
    "## 머신러닝 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8fc7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f33ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tsor = np.arange(7.0)\n",
    "tsor.ndim # 1.    # 텐서의 차원\n",
    "tsor.shape # (7,)  # 텐서의 크기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3576d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsor2 = np.arange(1.0, 13).reshape((4,3))\n",
    "tsor2.ndim #2\n",
    "tsor2.shape # (4,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1dde4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tsor3 = torch.arange(0.0, 7)\n",
    "tsor3.dim() # 1\n",
    "tsor3.shape  # torch.Size([7])\n",
    "tsor3.size() # torch.Size([7])\n",
    "tsor3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 4.,  5.],\n",
       "        [ 7.,  8.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(1,13.0).reshape((4,3))\n",
    "t.dim() #2\n",
    "t.size() # torch.Size([4, 3])\n",
    "t.shape # torch.Size([4, 3])\n",
    "\n",
    "t[:,1]\n",
    "t[:,1].size()\n",
    "t[:,:-1] # 마지막 차원 제외\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1c5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([3,3])\n",
    "m2 = torch.FloatTensor([2,2])\n",
    "m1 + m2 # tensor([5., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcbc1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([1,2])\n",
    "m2 = torch.FloatTensor([3])\n",
    "m1 + m2 # tensor([4., 5.]) 큰 size에 맞춰서 작은 사이즈가 중복되어 생김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342198b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m2 = torch.FloatTensor([[1],[2]]) # 2*1\n",
    "m1 + m2 # tensor([[2., 3.],\n",
    "        #         [5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1aacb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [11.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m2 = torch.FloatTensor([[1],[2]]) # 2*1\n",
    "\n",
    "m1.matmul(m2).shape # torch.Size([2, 1]) 내적 (dot 연산) -> matrix multiplication \n",
    "(m1 @ m2).shape # 위와 같은 연산\n",
    "torch.matmul(m1,m2)\n",
    "# torch.dot(m1,m2) 벡터끼리의 내적만 지원함 행렬곱은 안됨 -> 1D 전용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d77b36",
   "metadata": {},
   "source": [
    "#### 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c2b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 3.5000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([1,2])\n",
    "t.mean() # tensor(1.5000)\n",
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m1.mean()\n",
    "\n",
    "m1.mean(dim=0 ,dtype=torch.float) # tensor([2., 3.])\n",
    "m1.mean(dim=1 ,dtype=torch.float) # tensor([1.5000, 3.5000])\n",
    "# m1.mean(dim=2 ,dtype=torch.float) # Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
    "\n",
    "# dim=0이면 0번째 축(행 방향) 을 없애면서 계산,\n",
    "# dim=1이면 1번째 축(열 방향) 을 없애면서 계산\n",
    "m1.mean(dim=-1 ,dtype=torch.float) # tensor([1.5000, 3.5000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a46c61",
   "metadata": {},
   "source": [
    "#### 덧셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba69c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 7.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.FloatTensor([[1,2],[3,4]])\n",
    "t2.sum() #tensor(10.)\n",
    "t2.sum(dim=0) # tensor([4., 6.])\n",
    "t2.sum(dim=1) # tensor([3., 7.])\n",
    "t2.sum(dim=-1) # tensor([3., 7.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96421c8e",
   "metadata": {},
   "source": [
    "#### max, arxmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e8495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.FloatTensor([[1,2],[3,4]])\n",
    "t3.max() # tensor(4.)\n",
    "t3.max(dim=0) # torch.return_types.max(values=tensor([3., 4.]),indices=tensor([1, 1])) # indice= 최대값위치\n",
    "t3.max(dim=1) # torch.return_types.max(values=tensor([2., 4.]),(indices=tensor([1, 1]))\n",
    "\n",
    "t3.max(dim=0)[0] # tensor([3., 4.]) -> tensor\n",
    "t3.max(dim=0)[1] # tensor([1, 1]) -> indice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a70194",
   "metadata": {},
   "source": [
    "#### view - 원소의 수를 유지하며 텐서 크기 변경 (np.reshape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764e47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tt = np.arange(0,12).reshape((4,3))\n",
    "tt\n",
    "\n",
    "ft = torch.FloatTensor(tt)\n",
    "\n",
    "# tensor([[ 0.,  1.,  2.],\n",
    "#         [ 3.,  4.,  5.],\n",
    "#         [ 6.,  7.,  8.],\n",
    "#         [ 9., 10., 11.]])\n",
    "\n",
    "\n",
    "ft.shape # torch.Size([4, 3])\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba3e319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.],\n",
       "        [ 2.,  3.],\n",
       "        [ 4.,  5.],\n",
       "        [ 6.,  7.],\n",
       "        [ 8.,  9.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47f1825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,1,3]).shape # torch.Size([4, 1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044b6ca",
   "metadata": {},
   "source": [
    "#### squeeze -1 차원 제거, unsqueeze +1 차원추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4ac5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = ttt = torch.arange(1,4).reshape((3,1))\n",
    "\n",
    "ttt.shape #torch.Size([3, 1])\n",
    "ttt.squeeze().shape # torch.Size([3])\n",
    "\n",
    "\n",
    "tttt = torch.arange(1,4).reshape((3,1))\n",
    "# tensor([[1],\n",
    "#         [2],\n",
    "#         [3]])\n",
    "# torch.Size([3, 1])\n",
    "\n",
    "tttt.unsqueeze(0) # 인덱스가 0부터 시작하므로 0은 첫번째 차원을 의미한다.\n",
    "\n",
    "# tensor([[[1],\n",
    "#          [2],\n",
    "#          [3]]])\n",
    "# torch.Size([1, 3, 1])\n",
    "\n",
    "tttt.unsqueeze(1)\n",
    "\n",
    "# tensor([[[1]],\n",
    "\n",
    "#         [[2]],\n",
    "\n",
    "        # [[3]]])\n",
    "tttt.unsqueeze(1).shape\n",
    "\n",
    "#torch.Size([3, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c34597b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tttt.unsqueeze(-1).shape # torch.Size([3, 1, 1])\n",
    "\n",
    "tttt.view(1,-1) # torch.Size([1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460bdb0a",
   "metadata": {},
   "source": [
    "#### 타입캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d809128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = torch.LongTensor([1,2,3,4]) #tensor([1, 2, 3, 4])\n",
    "ft.float() # tensor([1., 2., 3., 4.])\n",
    "\n",
    "bt = torch.ByteTensor([True, False, False, True]) # tensor([1, 0, 0, 1], dtype=torch.uint8)\n",
    "bt.long() # tensor([1, 0, 0, 1])\n",
    "bt.float() # tensor([1., 0., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe31633",
   "metadata": {},
   "source": [
    "#### tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7407cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "y = torch.FloatTensor([[5,6],[7,8]])\n",
    "\n",
    "torch.cat((x,y)) # dim= 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf9f4cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 5., 6.],\n",
       "        [3., 4., 7., 8.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39978e8a",
   "metadata": {},
   "source": [
    "#### 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38524749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "torch.stack((x,y,z)) #1+1+1 차원 -> 2차원\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5441c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x.unsqueeze(0),y.unsqueeze(0), z.unsqueeze(0))) # 위와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dab2b",
   "metadata": {},
   "source": [
    "#### one_like, zeros_like -0, 1로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "396b34a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.FloatTensor([[0,1,2],[2,1,0]]) # 2 * 3 텐서\n",
    "torch.ones_like(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54be3796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f03d90",
   "metadata": {},
   "source": [
    "#### in place operation 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0670f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "x.mul(2)\n",
    "x # 원본은 그대로임\n",
    "x.mul_(2)\n",
    "x # 원본이 변경됨( in_place version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00198eef",
   "metadata": {},
   "source": [
    "## 선형회귀와 다중미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]]) # 3*1\n",
    "y_train = torch.FloatTensor([[2],[4],[6]]) # 3*1\n",
    "\n",
    "x_train.shape # torch.Size([3, 1])\n",
    "\n",
    "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True) # tensor([0.], requires_grad=True)\n",
    "W3 = torch.zeros(0, requires_grad=True) # tensor([], requires_grad=True)\n",
    "W2 = torch.zeros((3,3), requires_grad=True) \n",
    "\n",
    "# tensor([[0., 0., 0.],\n",
    "#         [0., 0., 0.],\n",
    "#         [0., 0., 0.]], requires_grad=True)\n",
    "\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# 경사하강법 적용할 optimizer 함수 SGD를 정의\n",
    "\n",
    "optimizer = optim.SGD([W,b],lr=0.01) # SGD - Stochastic Gradient Descent\n",
    "\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# tensor([[0.],\n",
    "#         [0.],\n",
    "#         [0.]], grad_fn=<AddBackward0>)\n",
    "\n",
    "# 비용함수 = average(가설값 - 실제데이터)^2\n",
    "\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "# tensor(18.6667, grad_fn=<MeanBackward0>)\n",
    "\n",
    "# gradient 0으로 초기화\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# 비용함수를 미분하여 gradient 계산\n",
    "\n",
    "cost.backward()\n",
    "\n",
    "# W, b 를 업데이트\n",
    "\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "15525f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 W: 0.186667, b: 0.080, Cost: 18.666666\n",
      "Epoch  100/2000 W: 1.745691, b: 0.578, Cost: 0.048171\n",
      "Epoch  200/2000 W: 1.800099, b: 0.454, Cost: 0.029767\n",
      "Epoch  300/2000 W: 1.842860, b: 0.357, Cost: 0.018394\n",
      "Epoch  400/2000 W: 1.876473, b: 0.281, Cost: 0.011366\n",
      "Epoch  500/2000 W: 1.902897, b: 0.221, Cost: 0.007024\n",
      "Epoch  600/2000 W: 1.923668, b: 0.174, Cost: 0.004340\n",
      "Epoch  700/2000 W: 1.939996, b: 0.136, Cost: 0.002682\n",
      "Epoch  800/2000 W: 1.952832, b: 0.107, Cost: 0.001657\n",
      "Epoch  900/2000 W: 1.962921, b: 0.084, Cost: 0.001024\n",
      "Epoch 1000/2000 W: 1.970853, b: 0.066, Cost: 0.000633\n",
      "Epoch 1100/2000 W: 1.977087, b: 0.052, Cost: 0.000391\n",
      "Epoch 1200/2000 W: 1.981989, b: 0.041, Cost: 0.000242\n",
      "Epoch 1300/2000 W: 1.985842, b: 0.032, Cost: 0.000149\n",
      "Epoch 1400/2000 W: 1.988870, b: 0.025, Cost: 0.000092\n",
      "Epoch 1500/2000 W: 1.991251, b: 0.020, Cost: 0.000057\n",
      "Epoch 1600/2000 W: 1.993122, b: 0.016, Cost: 0.000035\n",
      "Epoch 1700/2000 W: 1.994594, b: 0.012, Cost: 0.000022\n",
      "Epoch 1800/2000 W: 1.995750, b: 0.010, Cost: 0.000013\n",
      "Epoch 1900/2000 W: 1.996659, b: 0.008, Cost: 0.000008\n",
      "Epoch 2000/2000 W: 1.997374, b: 0.006, Cost: 0.000005\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]]) # 3*1\n",
    "y_train = torch.FloatTensor([[2],[4],[6]]) # 3*1\n",
    "\n",
    "x_train.shape # torch.Size([3, 1])\n",
    "\n",
    "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True) # tensor([0.], requires_grad=True)\n",
    "\n",
    "\n",
    "# tensor([[0., 0., 0.],\n",
    "#         [0., 0., 0.],\n",
    "#         [0., 0., 0.]], requires_grad=True)\n",
    "\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# 경사하강법 적용할 optimizer 함수 SGD를 정의\n",
    "\n",
    "optimizer = optim.SGD([W,b],lr=0.01) # SGD - Stochastic Gradient Descent\n",
    "\n",
    "nb_epochs = 2000 # 원하는 만큼 경사하강법을 반복\n",
    "\n",
    "for epoch in range(nb_epochs +1) :\n",
    "    \n",
    "    hypothesis = x_train * W + b\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#   100번 마다 로그 출력\n",
    "    if epoch % 100 == 0 :\n",
    "      print(\"Epoch {:4d}/{} W: {:3f}, b: {:.3f}, Cost: {:6f}\".format(epoch, nb_epochs, W.item(), b.item(), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7c871a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost:29661.800781\n",
      "Epoch  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost:1.563628\n",
      "Epoch  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost:1.497595\n",
      "Epoch  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost:1.435044\n",
      "Epoch  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost:1.375726\n",
      "Epoch  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost:1.319507\n",
      "Epoch  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost:1.266222\n",
      "Epoch  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost:1.215703\n",
      "Epoch  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost:1.167810\n",
      "Epoch  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost:1.122429\n",
      "Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost:1.079390\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "# 훈련 데이터\n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 가중치 w와 편향 b 초기화\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD( [ w1, w2, w3, b] , lr=0.00001 )\n",
    "\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "# H(x) 계산\n",
    "  hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "# cost 계산\n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "# cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "# 100번마다 로그 출력\n",
    "  if epoch % 100 == 0:\n",
    "    print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost:{:.6f}'.format(\n",
    "\n",
    "  epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(),cost.item()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "[93, 88, 93],\n",
    "[89, 91, 80],\n",
    "[96, 98, 100],\n",
    "[73, 66, 70]])\n",
    "\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "# H(x) 계산, 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
    "  hypothesis = x_train.matmul(W) + b\n",
    "  \n",
    "  # cost 계산\n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "  # cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "\n",
    "print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "))\n",
    "# 학습하여 산출된 가중치( W1~3 과 b값) 에 대하여 임의의 입력 값 적용\n",
    "# no_grad() block 내 모든 연산수행시 역전파(기울기 계산) 비활성화\n",
    "#\n",
    "with torch.no_grad():\n",
    "# 예측하고 싶은 임의의 입력값\n",
    "  new_input = torch.FloatTensor([[75, 85, 72]])\n",
    "  prediction = new_input.matmul(W) + b\n",
    "  \n",
    "print('Predicted value for input {}: {}'.format(new_input.squeeze().tolist(),prediction.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1496e",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch는 기본적으로 모든 Tensor 연산을 추적(trace) 합니다.\n",
    "왜냐하면 backward()로 역전파(gradient 계산)를 하기 위해서죠.\n",
    "\n",
    "하지만 예측할 때는 더 이상 학습하지 않으므로,\n",
    "기울기를 계산할 필요가 없습니다 → 메모리 절약 + 속도 향상.\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42268ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter...\n",
      "hello obama\n",
      "hello trump\n",
      "exit...\n"
     ]
    }
   ],
   "source": [
    "class Hello:\n",
    "    def __enter__(self):\n",
    "        # 사용할 자원을 가져오거나 만든다(핸들러 등)\n",
    "        print('enter...')\n",
    "        return self # 반환값이 있어야 VARIABLE를 블록내에서 사용할 수 있다\n",
    "        \n",
    "    def sayHello(self, name):\n",
    "        # 자원을 사용한다. ex) 인사한다\n",
    "        print('hello ' + name)\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # 마지막 처리를 한다(자원반납 등)\n",
    "        print('exit...')\n",
    "\n",
    "with Hello() as h:\n",
    "    h.sayHello('obama')\n",
    "    h.sayHello('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "20f737de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)]\n",
      "Epoch    0/1800 Cost: 13.103541\n",
      "Epoch  100/1800 Cost: 0.002791\n",
      "Epoch  200/1800 Cost: 0.001724\n",
      "Epoch  300/1800 Cost: 0.001066\n",
      "Epoch  400/1800 Cost: 0.000658\n",
      "Epoch  500/1800 Cost: 0.000407\n",
      "Epoch  600/1800 Cost: 0.000251\n",
      "Epoch  700/1800 Cost: 0.000155\n",
      "Epoch  800/1800 Cost: 0.000096\n",
      "Epoch  900/1800 Cost: 0.000059\n",
      "Epoch 1000/1800 Cost: 0.000037\n",
      "Epoch 1100/1800 Cost: 0.000023\n",
      "Epoch 1200/1800 Cost: 0.000014\n",
      "Epoch 1300/1800 Cost: 0.000009\n",
      "Epoch 1400/1800 Cost: 0.000005\n",
      "Epoch 1500/1800 Cost: 0.000003\n",
      "Epoch 1600/1800 Cost: 0.000002\n",
      "Epoch 1700/1800 Cost: 0.000001\n",
      "Epoch 1800/1800 Cost: 0.000001\n",
      "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9982]], grad_fn=<AddmmBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[1.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0023], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1) # random seed 고정값\n",
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
    "model = nn.Linear(1,1)\n",
    "print(list(model.parameters()))\n",
    "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
    "nb_epochs = 1800\n",
    "for epoch in range(nb_epochs+1):\n",
    "# H(x) 계산\n",
    "  prediction = model(x_train)\n",
    "# cost 계산\n",
    "  cost = F.mse_loss(prediction, y_train) # 평균 제곱 오차 함수(pytorch 내장)\n",
    "# cost로 H(x) 개선하는 부분\n",
    "  optimizer.zero_grad() # gradient를 0으로 초기화\n",
    "# 비용 함수를 미분하여 gradient 계산\n",
    "  cost.backward() # backward 연산\n",
    "# W와 b를 업데이트\n",
    "  optimizer.step()\n",
    "  if epoch % 100 == 0:\n",
    "  # 100번마다 로그 출력\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()\n",
    "  ))\n",
    "    \n",
    "# 임의의 입력 4를 선언\n",
    "new_var = torch.FloatTensor([[4.0]])\n",
    "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) # forward 연산\n",
    "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된것\n",
    "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e3a7433f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2710], requires_grad=True)]\n",
      "Epoch    0/2000 Cost: 31667.597656\n",
      "Epoch  100/2000 Cost: 0.225990\n",
      "Epoch  200/2000 Cost: 0.223910\n",
      "Epoch  300/2000 Cost: 0.221936\n",
      "Epoch  400/2000 Cost: 0.220061\n",
      "Epoch  500/2000 Cost: 0.218269\n",
      "Epoch  600/2000 Cost: 0.216570\n",
      "Epoch  700/2000 Cost: 0.214958\n",
      "Epoch  800/2000 Cost: 0.213411\n",
      "Epoch  900/2000 Cost: 0.211951\n",
      "Epoch 1000/2000 Cost: 0.210564\n",
      "Epoch 1100/2000 Cost: 0.209231\n",
      "Epoch 1200/2000 Cost: 0.207970\n",
      "Epoch 1300/2000 Cost: 0.206765\n",
      "Epoch 1400/2000 Cost: 0.205617\n",
      "Epoch 1500/2000 Cost: 0.204521\n",
      "Epoch 1600/2000 Cost: 0.203483\n",
      "Epoch 1700/2000 Cost: 0.202489\n",
      "Epoch 1800/2000 Cost: 0.201539\n",
      "Epoch 1900/2000 Cost: 0.200637\n",
      "Epoch 2000/2000 Cost: 0.199773\n",
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.2305]], grad_fn=<AddmmBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2802], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "  [93, 88, 93],\n",
    "  [89, 91, 90],\n",
    "  [96, 98, 100],\n",
    "  [73, 66, 70]])\n",
    "\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "model = nn.Linear(3,1)\n",
    "print(list(model.parameters()))\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00001)\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "# H(x) 계산\n",
    "  prediction = model(x_train) #model(x_train)은 model.forward(x_train)와 동일\n",
    "  \n",
    "  # cost 계산\n",
    "  cost = F.mse_loss(prediction, y_train) # 평균 제곱 오차 함수(pyTorch내장)\n",
    "  # cost로 H(x) 개선하는 부분\n",
    "  optimizer.zero_grad() # gradient를 0으로 초기화\n",
    "  cost.backward() # 비용 함수를 미분하여 gradient 계산\n",
    "  optimizer.step() # W와 b를 업데이트\n",
    "  if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))\n",
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var = torch.FloatTensor([[73, 80, 75]])\n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var)\n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y)\n",
    "print(list(model.parameters()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langCh-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
