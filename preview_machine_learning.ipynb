{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2716cf",
   "metadata": {},
   "source": [
    "## 머신러닝 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8fc7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f33ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tsor = np.arange(7.0)\n",
    "tsor.ndim # 1.    # 텐서의 차원\n",
    "tsor.shape # (7,)  # 텐서의 크기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3576d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsor2 = np.arange(1.0, 13).reshape((4,3))\n",
    "tsor2.ndim #2\n",
    "tsor2.shape # (4,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1dde4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tsor3 = torch.arange(0.0, 7)\n",
    "tsor3.dim() # 1\n",
    "tsor3.shape  # torch.Size([7])\n",
    "tsor3.size() # torch.Size([7])\n",
    "tsor3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 4.,  5.],\n",
       "        [ 7.,  8.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(1,13.0).reshape((4,3))\n",
    "t.dim() #2\n",
    "t.size() # torch.Size([4, 3])\n",
    "t.shape # torch.Size([4, 3])\n",
    "\n",
    "t[:,1]\n",
    "t[:,1].size()\n",
    "t[:,:-1] # 마지막 차원 제외\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1c5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([3,3])\n",
    "m2 = torch.FloatTensor([2,2])\n",
    "m1 + m2 # tensor([5., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcbc1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([1,2])\n",
    "m2 = torch.FloatTensor([3])\n",
    "m1 + m2 # tensor([4., 5.]) 큰 size에 맞춰서 작은 사이즈가 중복되어 생김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342198b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m2 = torch.FloatTensor([[1],[2]]) # 2*1\n",
    "m1 + m2 # tensor([[2., 3.],\n",
    "        #         [5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1aacb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [11.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m2 = torch.FloatTensor([[1],[2]]) # 2*1\n",
    "\n",
    "m1.matmul(m2).shape # torch.Size([2, 1]) 내적 (dot 연산) -> matrix multiplication \n",
    "(m1 @ m2).shape # 위와 같은 연산\n",
    "torch.matmul(m1,m2)\n",
    "# torch.dot(m1,m2) 벡터끼리의 내적만 지원함 행렬곱은 안됨 -> 1D 전용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d77b36",
   "metadata": {},
   "source": [
    "#### 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c2b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 3.5000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([1,2])\n",
    "t.mean() # tensor(1.5000)\n",
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m1.mean()\n",
    "\n",
    "m1.mean(dim=0 ,dtype=torch.float) # tensor([2., 3.])\n",
    "m1.mean(dim=1 ,dtype=torch.float) # tensor([1.5000, 3.5000])\n",
    "# m1.mean(dim=2 ,dtype=torch.float) # Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
    "\n",
    "# dim=0이면 0번째 축(행 방향) 을 없애면서 계산,\n",
    "# dim=1이면 1번째 축(열 방향) 을 없애면서 계산\n",
    "m1.mean(dim=-1 ,dtype=torch.float) # tensor([1.5000, 3.5000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a46c61",
   "metadata": {},
   "source": [
    "#### 덧셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba69c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 7.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.FloatTensor([[1,2],[3,4]])\n",
    "t2.sum() #tensor(10.)\n",
    "t2.sum(dim=0) # tensor([4., 6.])\n",
    "t2.sum(dim=1) # tensor([3., 7.])\n",
    "t2.sum(dim=-1) # tensor([3., 7.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96421c8e",
   "metadata": {},
   "source": [
    "#### max, arxmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e8495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.FloatTensor([[1,2],[3,4]])\n",
    "t3.max() # tensor(4.)\n",
    "t3.max(dim=0) # torch.return_types.max(values=tensor([3., 4.]),indices=tensor([1, 1])) # indice= 최대값위치\n",
    "t3.max(dim=1) # torch.return_types.max(values=tensor([2., 4.]),(indices=tensor([1, 1]))\n",
    "\n",
    "t3.max(dim=0)[0] # tensor([3., 4.]) -> tensor\n",
    "t3.max(dim=0)[1] # tensor([1, 1]) -> indice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a70194",
   "metadata": {},
   "source": [
    "#### view - 원소의 수를 유지하며 텐서 크기 변경 (np.reshape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764e47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tt = np.arange(0,12).reshape((4,3))\n",
    "tt\n",
    "\n",
    "ft = torch.FloatTensor(tt)\n",
    "\n",
    "# tensor([[ 0.,  1.,  2.],\n",
    "#         [ 3.,  4.,  5.],\n",
    "#         [ 6.,  7.,  8.],\n",
    "#         [ 9., 10., 11.]])\n",
    "\n",
    "\n",
    "ft.shape # torch.Size([4, 3])\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba3e319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.],\n",
       "        [ 2.,  3.],\n",
       "        [ 4.,  5.],\n",
       "        [ 6.,  7.],\n",
       "        [ 8.,  9.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47f1825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,1,3]).shape # torch.Size([4, 1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044b6ca",
   "metadata": {},
   "source": [
    "#### squeeze -1 차원 제거, unsqueeze +1 차원추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4ac5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = ttt = torch.arange(1,4).reshape((3,1))\n",
    "\n",
    "ttt.shape #torch.Size([3, 1])\n",
    "ttt.squeeze().shape # torch.Size([3])\n",
    "\n",
    "\n",
    "tttt = torch.arange(1,4).reshape((3,1))\n",
    "# tensor([[1],\n",
    "#         [2],\n",
    "#         [3]])\n",
    "# torch.Size([3, 1])\n",
    "\n",
    "tttt.unsqueeze(0) # 인덱스가 0부터 시작하므로 0은 첫번째 차원을 의미한다.\n",
    "\n",
    "# tensor([[[1],\n",
    "#          [2],\n",
    "#          [3]]])\n",
    "# torch.Size([1, 3, 1])\n",
    "\n",
    "tttt.unsqueeze(1)\n",
    "\n",
    "# tensor([[[1]],\n",
    "\n",
    "#         [[2]],\n",
    "\n",
    "        # [[3]]])\n",
    "tttt.unsqueeze(1).shape\n",
    "\n",
    "#torch.Size([3, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c34597b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tttt.unsqueeze(-1).shape # torch.Size([3, 1, 1])\n",
    "\n",
    "tttt.view(1,-1) # torch.Size([1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460bdb0a",
   "metadata": {},
   "source": [
    "#### 타입캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d809128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = torch.LongTensor([1,2,3,4]) #tensor([1, 2, 3, 4])\n",
    "ft.float() # tensor([1., 2., 3., 4.])\n",
    "\n",
    "bt = torch.ByteTensor([True, False, False, True]) # tensor([1, 0, 0, 1], dtype=torch.uint8)\n",
    "bt.long() # tensor([1, 0, 0, 1])\n",
    "bt.float() # tensor([1., 0., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe31633",
   "metadata": {},
   "source": [
    "#### tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7407cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "y = torch.FloatTensor([[5,6],[7,8]])\n",
    "\n",
    "torch.cat((x,y)) # dim= 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf9f4cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 5., 6.],\n",
       "        [3., 4., 7., 8.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39978e8a",
   "metadata": {},
   "source": [
    "#### 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38524749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "torch.stack((x,y,z)) #1+1+1 차원 -> 2차원\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5441c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x.unsqueeze(0),y.unsqueeze(0), z.unsqueeze(0))) # 위와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dab2b",
   "metadata": {},
   "source": [
    "#### one_like, zeros_like -0, 1로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "396b34a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.FloatTensor([[0,1,2],[2,1,0]]) # 2 * 3 텐서\n",
    "torch.ones_like(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54be3796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f03d90",
   "metadata": {},
   "source": [
    "#### in place operation 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0670f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "x.mul(2)\n",
    "x # 원본은 그대로임\n",
    "x.mul_(2)\n",
    "x # 원본이 변경됨( in_place version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00198eef",
   "metadata": {},
   "source": [
    "## 선형회귀와 다중미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]]) # 3*1\n",
    "y_train = torch.FloatTensor([[2],[4],[6]]) # 3*1\n",
    "\n",
    "x_train.shape # torch.Size([3, 1])\n",
    "\n",
    "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True) # tensor([0.], requires_grad=True)\n",
    "W3 = torch.zeros(0, requires_grad=True) # tensor([], requires_grad=True)\n",
    "W2 = torch.zeros((3,3), requires_grad=True) \n",
    "\n",
    "# tensor([[0., 0., 0.],\n",
    "#         [0., 0., 0.],\n",
    "#         [0., 0., 0.]], requires_grad=True)\n",
    "\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# 경사하강법 적용할 optimizer 함수 SGD를 정의\n",
    "\n",
    "optimizer = optim.SGD([W,b],lr=0.01) # SGD - Stochastic Gradient Descent\n",
    "\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# tensor([[0.],\n",
    "#         [0.],\n",
    "#         [0.]], grad_fn=<AddBackward0>)\n",
    "\n",
    "# 비용함수 = average(가설값 - 실제데이터)^2\n",
    "\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "# tensor(18.6667, grad_fn=<MeanBackward0>)\n",
    "\n",
    "# gradient 0으로 초기화\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# 비용함수를 미분하여 gradient 계산\n",
    "\n",
    "cost.backward()\n",
    "\n",
    "# W, b 를 업데이트\n",
    "\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "15525f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 W: 0.186667, b: 0.080, Cost: 18.666666\n",
      "Epoch  100/2000 W: 1.745691, b: 0.578, Cost: 0.048171\n",
      "Epoch  200/2000 W: 1.800099, b: 0.454, Cost: 0.029767\n",
      "Epoch  300/2000 W: 1.842860, b: 0.357, Cost: 0.018394\n",
      "Epoch  400/2000 W: 1.876473, b: 0.281, Cost: 0.011366\n",
      "Epoch  500/2000 W: 1.902897, b: 0.221, Cost: 0.007024\n",
      "Epoch  600/2000 W: 1.923668, b: 0.174, Cost: 0.004340\n",
      "Epoch  700/2000 W: 1.939996, b: 0.136, Cost: 0.002682\n",
      "Epoch  800/2000 W: 1.952832, b: 0.107, Cost: 0.001657\n",
      "Epoch  900/2000 W: 1.962921, b: 0.084, Cost: 0.001024\n",
      "Epoch 1000/2000 W: 1.970853, b: 0.066, Cost: 0.000633\n",
      "Epoch 1100/2000 W: 1.977087, b: 0.052, Cost: 0.000391\n",
      "Epoch 1200/2000 W: 1.981989, b: 0.041, Cost: 0.000242\n",
      "Epoch 1300/2000 W: 1.985842, b: 0.032, Cost: 0.000149\n",
      "Epoch 1400/2000 W: 1.988870, b: 0.025, Cost: 0.000092\n",
      "Epoch 1500/2000 W: 1.991251, b: 0.020, Cost: 0.000057\n",
      "Epoch 1600/2000 W: 1.993122, b: 0.016, Cost: 0.000035\n",
      "Epoch 1700/2000 W: 1.994594, b: 0.012, Cost: 0.000022\n",
      "Epoch 1800/2000 W: 1.995750, b: 0.010, Cost: 0.000013\n",
      "Epoch 1900/2000 W: 1.996659, b: 0.008, Cost: 0.000008\n",
      "Epoch 2000/2000 W: 1.997374, b: 0.006, Cost: 0.000005\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]]) # 3*1\n",
    "y_train = torch.FloatTensor([[2],[4],[6]]) # 3*1\n",
    "\n",
    "x_train.shape # torch.Size([3, 1])\n",
    "\n",
    "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True) # tensor([0.], requires_grad=True)\n",
    "\n",
    "\n",
    "# tensor([[0., 0., 0.],\n",
    "#         [0., 0., 0.],\n",
    "#         [0., 0., 0.]], requires_grad=True)\n",
    "\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# 경사하강법 적용할 optimizer 함수 SGD를 정의\n",
    "\n",
    "optimizer = optim.SGD([W,b],lr=0.01) # SGD - Stochastic Gradient Descent\n",
    "\n",
    "nb_epochs = 2000 # 원하는 만큼 경사하강법을 반복\n",
    "\n",
    "for epoch in range(nb_epochs +1) :\n",
    "    \n",
    "    hypothesis = x_train * W + b\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#   100번 마다 로그 출력\n",
    "    if epoch % 100 == 0 :\n",
    "      print(\"Epoch {:4d}/{} W: {:3f}, b: {:.3f}, Cost: {:6f}\".format(epoch, nb_epochs, W.item(), b.item(), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7c871a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost:29661.800781\n",
      "Epoch  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost:1.563628\n",
      "Epoch  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost:1.497595\n",
      "Epoch  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost:1.435044\n",
      "Epoch  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost:1.375726\n",
      "Epoch  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost:1.319507\n",
      "Epoch  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost:1.266222\n",
      "Epoch  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost:1.215703\n",
      "Epoch  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost:1.167810\n",
      "Epoch  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost:1.122429\n",
      "Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost:1.079390\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "# 훈련 데이터\n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 가중치 w와 편향 b 초기화\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD( [ w1, w2, w3, b] , lr=0.00001 )\n",
    "\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "# H(x) 계산\n",
    "  hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "# cost 계산\n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "# cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "# 100번마다 로그 출력\n",
    "  if epoch % 100 == 0:\n",
    "    print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost:{:.6f}'.format(\n",
    "\n",
    "  epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(),cost.item()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "[93, 88, 93],\n",
    "[89, 91, 80],\n",
    "[96, 98, 100],\n",
    "[73, 66, 70]])\n",
    "\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "# H(x) 계산, 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
    "  hypothesis = x_train.matmul(W) + b\n",
    "  \n",
    "  # cost 계산\n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "  # cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "\n",
    "print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "))\n",
    "# 학습하여 산출된 가중치( W1~3 과 b값) 에 대하여 임의의 입력 값 적용\n",
    "# no_grad() block 내 모든 연산수행시 역전파(기울기 계산) 비활성화\n",
    "#\n",
    "with torch.no_grad():\n",
    "# 예측하고 싶은 임의의 입력값\n",
    "  new_input = torch.FloatTensor([[75, 85, 72]])\n",
    "  prediction = new_input.matmul(W) + b\n",
    "  \n",
    "print('Predicted value for input {}: {}'.format(new_input.squeeze().tolist(),prediction.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1496e",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch는 기본적으로 모든 Tensor 연산을 추적(trace) 합니다.\n",
    "왜냐하면 backward()로 역전파(gradient 계산)를 하기 위해서죠.\n",
    "\n",
    "하지만 예측할 때는 더 이상 학습하지 않으므로,\n",
    "기울기를 계산할 필요가 없습니다 → 메모리 절약 + 속도 향상.\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42268ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter...\n",
      "hello obama\n",
      "hello trump\n",
      "exit...\n"
     ]
    }
   ],
   "source": [
    "class Hello:\n",
    "    def __enter__(self):\n",
    "        # 사용할 자원을 가져오거나 만든다(핸들러 등)\n",
    "        print('enter...')\n",
    "        return self # 반환값이 있어야 VARIABLE를 블록내에서 사용할 수 있다\n",
    "        \n",
    "    def sayHello(self, name):\n",
    "        # 자원을 사용한다. ex) 인사한다\n",
    "        print('hello ' + name)\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # 마지막 처리를 한다(자원반납 등)\n",
    "        print('exit...')\n",
    "\n",
    "with Hello() as h:\n",
    "    h.sayHello('obama')\n",
    "    h.sayHello('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "20f737de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)]\n",
      "Epoch    0/1800 Cost: 13.103541\n",
      "Epoch  100/1800 Cost: 0.002791\n",
      "Epoch  200/1800 Cost: 0.001724\n",
      "Epoch  300/1800 Cost: 0.001066\n",
      "Epoch  400/1800 Cost: 0.000658\n",
      "Epoch  500/1800 Cost: 0.000407\n",
      "Epoch  600/1800 Cost: 0.000251\n",
      "Epoch  700/1800 Cost: 0.000155\n",
      "Epoch  800/1800 Cost: 0.000096\n",
      "Epoch  900/1800 Cost: 0.000059\n",
      "Epoch 1000/1800 Cost: 0.000037\n",
      "Epoch 1100/1800 Cost: 0.000023\n",
      "Epoch 1200/1800 Cost: 0.000014\n",
      "Epoch 1300/1800 Cost: 0.000009\n",
      "Epoch 1400/1800 Cost: 0.000005\n",
      "Epoch 1500/1800 Cost: 0.000003\n",
      "Epoch 1600/1800 Cost: 0.000002\n",
      "Epoch 1700/1800 Cost: 0.000001\n",
      "Epoch 1800/1800 Cost: 0.000001\n",
      "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9982]], grad_fn=<AddmmBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[1.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0023], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1) # random seed 고정값\n",
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
    "model = nn.Linear(1,1)\n",
    "print(list(model.parameters()))\n",
    "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
    "nb_epochs = 1800\n",
    "for epoch in range(nb_epochs+1):\n",
    "# H(x) 계산\n",
    "  prediction = model(x_train)\n",
    "# cost 계산\n",
    "  cost = F.mse_loss(prediction, y_train) # 평균 제곱 오차 함수(pytorch 내장)\n",
    "# cost로 H(x) 개선하는 부분\n",
    "  optimizer.zero_grad() # gradient를 0으로 초기화\n",
    "# 비용 함수를 미분하여 gradient 계산\n",
    "  cost.backward() # backward 연산\n",
    "# W와 b를 업데이트\n",
    "  optimizer.step()\n",
    "  if epoch % 100 == 0:\n",
    "  # 100번마다 로그 출력\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()\n",
    "  ))\n",
    "    \n",
    "# 임의의 입력 4를 선언\n",
    "new_var = torch.FloatTensor([[4.0]])\n",
    "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) # forward 연산\n",
    "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된것\n",
    "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e3a7433f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2710], requires_grad=True)]\n",
      "Epoch    0/2000 Cost: 31667.597656\n",
      "Epoch  100/2000 Cost: 0.225990\n",
      "Epoch  200/2000 Cost: 0.223910\n",
      "Epoch  300/2000 Cost: 0.221936\n",
      "Epoch  400/2000 Cost: 0.220061\n",
      "Epoch  500/2000 Cost: 0.218269\n",
      "Epoch  600/2000 Cost: 0.216570\n",
      "Epoch  700/2000 Cost: 0.214958\n",
      "Epoch  800/2000 Cost: 0.213411\n",
      "Epoch  900/2000 Cost: 0.211951\n",
      "Epoch 1000/2000 Cost: 0.210564\n",
      "Epoch 1100/2000 Cost: 0.209231\n",
      "Epoch 1200/2000 Cost: 0.207970\n",
      "Epoch 1300/2000 Cost: 0.206765\n",
      "Epoch 1400/2000 Cost: 0.205617\n",
      "Epoch 1500/2000 Cost: 0.204521\n",
      "Epoch 1600/2000 Cost: 0.203483\n",
      "Epoch 1700/2000 Cost: 0.202489\n",
      "Epoch 1800/2000 Cost: 0.201539\n",
      "Epoch 1900/2000 Cost: 0.200637\n",
      "Epoch 2000/2000 Cost: 0.199773\n",
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.2305]], grad_fn=<AddmmBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2802], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "  [93, 88, 93],\n",
    "  [89, 91, 90],\n",
    "  [96, 98, 100],\n",
    "  [73, 66, 70]])\n",
    "\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "model = nn.Linear(3,1)\n",
    "print(list(model.parameters()))\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00001)\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "# H(x) 계산\n",
    "  prediction = model(x_train) #model(x_train)은 model.forward(x_train)와 동일\n",
    "  \n",
    "  # cost 계산\n",
    "  cost = F.mse_loss(prediction, y_train) # 평균 제곱 오차 함수(pyTorch내장)\n",
    "  # cost로 H(x) 개선하는 부분\n",
    "  optimizer.zero_grad() # gradient를 0으로 초기화\n",
    "  cost.backward() # 비용 함수를 미분하여 gradient 계산\n",
    "  optimizer.step() # W와 b를 업데이트\n",
    "  if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))\n",
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var = torch.FloatTensor([[73, 80, 75]])\n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var)\n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c84182fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 W: 0.698160 b: -0.353161 Cost: 19.612261\n",
      "Epoch:   10 W: 1.699324 b: 0.163836 Cost: 2.767684\n",
      "Epoch:   20 W: 1.989414 b: 0.366209 Cost: 1.121449\n",
      "Epoch:   30 W: 2.060531 b: 0.470479 Cost: 0.924376\n",
      "Epoch:   40 W: 2.064516 b: 0.543481 Cost: 0.867188\n",
      "Epoch:   50 W: 2.048213 b: 0.605863 Cost: 0.825124\n",
      "Epoch:   60 W: 2.026067 b: 0.664022 Cost: 0.786222\n",
      "Epoch:   70 W: 2.002524 b: 0.719951 Cost: 0.749260\n",
      "Epoch:   80 W: 1.978948 b: 0.774289 Cost: 0.714046\n",
      "Epoch:   90 W: 1.955749 b: 0.827255 Cost: 0.680489\n",
      "Epoch:  100 W: 1.933046 b: 0.878936 Cost: 0.648508\n",
      "Epoch:  110 W: 1.910865 b: 0.929380 Cost: 0.618031\n",
      "Epoch:  120 W: 1.889206 b: 0.978622 Cost: 0.588985\n",
      "Epoch:  130 W: 1.868061 b: 1.026693 Cost: 0.561305\n",
      "Epoch:  140 W: 1.847418 b: 1.073620 Cost: 0.534926\n",
      "Epoch:  150 W: 1.827265 b: 1.119431 Cost: 0.509786\n",
      "Epoch:  160 W: 1.807592 b: 1.164153 Cost: 0.485828\n",
      "Epoch:  170 W: 1.788387 b: 1.207811 Cost: 0.462996\n",
      "Epoch:  180 W: 1.769638 b: 1.250431 Cost: 0.441237\n",
      "Epoch:  190 W: 1.751336 b: 1.292037 Cost: 0.420501\n",
      "Epoch:  200 W: 1.733468 b: 1.332654 Cost: 0.400739\n",
      "Epoch:  210 W: 1.716026 b: 1.372305 Cost: 0.381906\n",
      "Epoch:  220 W: 1.698998 b: 1.411013 Cost: 0.363957\n",
      "Epoch:  230 W: 1.682375 b: 1.448801 Cost: 0.346853\n",
      "Epoch:  240 W: 1.666148 b: 1.485690 Cost: 0.330552\n",
      "Epoch:  250 W: 1.650306 b: 1.521701 Cost: 0.315017\n",
      "Epoch:  260 W: 1.634841 b: 1.556857 Cost: 0.300213\n",
      "Epoch:  270 W: 1.619744 b: 1.591176 Cost: 0.286103\n",
      "Epoch:  280 W: 1.605006 b: 1.624679 Cost: 0.272658\n",
      "Epoch:  290 W: 1.590618 b: 1.657386 Cost: 0.259844\n",
      "Epoch:  300 W: 1.576573 b: 1.689314 Cost: 0.247632\n",
      "Epoch:  310 W: 1.562861 b: 1.720484 Cost: 0.235994\n",
      "Epoch:  320 W: 1.549476 b: 1.750912 Cost: 0.224904\n",
      "Epoch:  330 W: 1.536409 b: 1.780616 Cost: 0.214334\n",
      "Epoch:  340 W: 1.523653 b: 1.809614 Cost: 0.204261\n",
      "Epoch:  350 W: 1.511200 b: 1.837923 Cost: 0.194661\n",
      "Epoch:  360 W: 1.499043 b: 1.865558 Cost: 0.185513\n",
      "Epoch:  370 W: 1.487175 b: 1.892536 Cost: 0.176795\n",
      "Epoch:  380 W: 1.475590 b: 1.918873 Cost: 0.168486\n",
      "Epoch:  390 W: 1.464280 b: 1.944583 Cost: 0.160568\n",
      "Epoch:  400 W: 1.453239 b: 1.969682 Cost: 0.153021\n",
      "Epoch:  410 W: 1.442460 b: 1.994184 Cost: 0.145830\n",
      "Epoch:  420 W: 1.431938 b: 2.018103 Cost: 0.138977\n",
      "Epoch:  430 W: 1.421666 b: 2.041453 Cost: 0.132445\n",
      "Epoch:  440 W: 1.411639 b: 2.064248 Cost: 0.126221\n",
      "Epoch:  450 W: 1.401850 b: 2.086501 Cost: 0.120289\n",
      "Epoch:  460 W: 1.392293 b: 2.108225 Cost: 0.114636\n",
      "Epoch:  470 W: 1.382964 b: 2.129432 Cost: 0.109249\n",
      "Epoch:  480 W: 1.373857 b: 2.150135 Cost: 0.104114\n",
      "Epoch:  490 W: 1.364966 b: 2.170346 Cost: 0.099221\n",
      "Epoch:  500 W: 1.356287 b: 2.190075 Cost: 0.094558\n",
      "Epoch:  510 W: 1.347814 b: 2.209336 Cost: 0.090114\n",
      "Epoch:  520 W: 1.339543 b: 2.228139 Cost: 0.085879\n",
      "Epoch:  530 W: 1.331468 b: 2.246495 Cost: 0.081843\n",
      "Epoch:  540 W: 1.323586 b: 2.264414 Cost: 0.077997\n",
      "Epoch:  550 W: 1.315891 b: 2.281907 Cost: 0.074331\n",
      "Epoch:  560 W: 1.308378 b: 2.298983 Cost: 0.070838\n",
      "Epoch:  570 W: 1.301045 b: 2.315654 Cost: 0.067509\n",
      "Epoch:  580 W: 1.293886 b: 2.331929 Cost: 0.064336\n",
      "Epoch:  590 W: 1.286897 b: 2.347816 Cost: 0.061313\n",
      "Epoch:  600 W: 1.280074 b: 2.363326 Cost: 0.058431\n",
      "Epoch:  610 W: 1.273414 b: 2.378466 Cost: 0.055685\n",
      "Epoch:  620 W: 1.266912 b: 2.393247 Cost: 0.053068\n",
      "Epoch:  630 W: 1.260564 b: 2.407677 Cost: 0.050574\n",
      "Epoch:  640 W: 1.254368 b: 2.421762 Cost: 0.048197\n",
      "Epoch:  650 W: 1.248319 b: 2.435513 Cost: 0.045932\n",
      "Epoch:  660 W: 1.242413 b: 2.448938 Cost: 0.043774\n",
      "Epoch:  670 W: 1.236648 b: 2.462042 Cost: 0.041716\n",
      "Epoch:  680 W: 1.231021 b: 2.474835 Cost: 0.039756\n",
      "Epoch:  690 W: 1.225527 b: 2.487324 Cost: 0.037887\n",
      "Epoch:  700 W: 1.220164 b: 2.499516 Cost: 0.036107\n",
      "Epoch:  710 W: 1.214928 b: 2.511418 Cost: 0.034410\n",
      "Epoch:  720 W: 1.209817 b: 2.523037 Cost: 0.032793\n",
      "Epoch:  730 W: 1.204827 b: 2.534379 Cost: 0.031252\n",
      "Epoch:  740 W: 1.199956 b: 2.545452 Cost: 0.029783\n",
      "Epoch:  750 W: 1.195201 b: 2.556262 Cost: 0.028383\n",
      "Epoch:  760 W: 1.190559 b: 2.566814 Cost: 0.027049\n",
      "Epoch:  770 W: 1.186028 b: 2.577115 Cost: 0.025778\n",
      "Epoch:  780 W: 1.181604 b: 2.587172 Cost: 0.024567\n",
      "Epoch:  790 W: 1.177285 b: 2.596989 Cost: 0.023412\n",
      "Epoch:  800 W: 1.173069 b: 2.606573 Cost: 0.022312\n",
      "Epoch:  810 W: 1.168953 b: 2.615929 Cost: 0.021263\n",
      "Epoch:  820 W: 1.164936 b: 2.625063 Cost: 0.020264\n",
      "Epoch:  830 W: 1.161013 b: 2.633979 Cost: 0.019312\n",
      "Epoch:  840 W: 1.157184 b: 2.642683 Cost: 0.018404\n",
      "Epoch:  850 W: 1.153446 b: 2.651181 Cost: 0.017539\n",
      "Epoch:  860 W: 1.149797 b: 2.659476 Cost: 0.016715\n",
      "Epoch:  870 W: 1.146235 b: 2.667574 Cost: 0.015929\n",
      "Epoch:  880 W: 1.142757 b: 2.675480 Cost: 0.015181\n",
      "Epoch:  890 W: 1.139362 b: 2.683197 Cost: 0.014467\n",
      "Epoch:  900 W: 1.136048 b: 2.690731 Cost: 0.013787\n",
      "Epoch:  910 W: 1.132812 b: 2.698086 Cost: 0.013139\n",
      "Epoch:  920 W: 1.129654 b: 2.705266 Cost: 0.012522\n",
      "Epoch:  930 W: 1.126571 b: 2.712274 Cost: 0.011933\n",
      "Epoch:  940 W: 1.123561 b: 2.719117 Cost: 0.011373\n",
      "Epoch:  950 W: 1.120623 b: 2.725796 Cost: 0.010838\n",
      "Epoch:  960 W: 1.117754 b: 2.732317 Cost: 0.010329\n",
      "Epoch:  970 W: 1.114954 b: 2.738683 Cost: 0.009843\n",
      "Epoch:  980 W: 1.112220 b: 2.744898 Cost: 0.009381\n",
      "Epoch:  990 W: 1.109551 b: 2.750964 Cost: 0.008940\n",
      "Epoch: 1000 W: 1.106946 b: 2.756886 Cost: 0.008520\n",
      "Epoch: 1010 W: 1.104403 b: 2.762668 Cost: 0.008119\n",
      "Epoch: 1020 W: 1.101920 b: 2.768312 Cost: 0.007738\n",
      "Epoch: 1030 W: 1.099496 b: 2.773822 Cost: 0.007374\n",
      "Epoch: 1040 W: 1.097130 b: 2.779201 Cost: 0.007028\n",
      "Epoch: 1050 W: 1.094820 b: 2.784451 Cost: 0.006697\n",
      "Epoch: 1060 W: 1.092565 b: 2.789577 Cost: 0.006383\n",
      "Epoch: 1070 W: 1.090364 b: 2.794581 Cost: 0.006083\n",
      "Epoch: 1080 W: 1.088215 b: 2.799466 Cost: 0.005797\n",
      "Epoch: 1090 W: 1.086118 b: 2.804235 Cost: 0.005524\n",
      "Epoch: 1100 W: 1.084069 b: 2.808890 Cost: 0.005265\n",
      "Epoch: 1110 W: 1.082070 b: 2.813435 Cost: 0.005017\n",
      "Epoch: 1120 W: 1.080119 b: 2.817872 Cost: 0.004781\n",
      "Epoch: 1130 W: 1.078213 b: 2.822203 Cost: 0.004557\n",
      "Epoch: 1140 W: 1.076353 b: 2.826431 Cost: 0.004343\n",
      "Epoch: 1150 W: 1.074537 b: 2.830559 Cost: 0.004139\n",
      "Epoch: 1160 W: 1.072765 b: 2.834588 Cost: 0.003944\n",
      "Epoch: 1170 W: 1.071034 b: 2.838522 Cost: 0.003759\n",
      "Epoch: 1180 W: 1.069345 b: 2.842362 Cost: 0.003582\n",
      "Epoch: 1190 W: 1.067696 b: 2.846111 Cost: 0.003414\n",
      "Epoch: 1200 W: 1.066086 b: 2.849770 Cost: 0.003253\n",
      "Epoch: 1210 W: 1.064515 b: 2.853343 Cost: 0.003100\n",
      "Epoch: 1220 W: 1.062981 b: 2.856831 Cost: 0.002955\n",
      "Epoch: 1230 W: 1.061483 b: 2.860235 Cost: 0.002816\n",
      "Epoch: 1240 W: 1.060021 b: 2.863559 Cost: 0.002683\n",
      "Epoch: 1250 W: 1.058593 b: 2.866804 Cost: 0.002557\n",
      "Epoch: 1260 W: 1.057200 b: 2.869971 Cost: 0.002437\n",
      "Epoch: 1270 W: 1.055840 b: 2.873063 Cost: 0.002323\n",
      "Epoch: 1280 W: 1.054512 b: 2.876082 Cost: 0.002213\n",
      "Epoch: 1290 W: 1.053215 b: 2.879029 Cost: 0.002109\n",
      "Epoch: 1300 W: 1.051950 b: 2.881906 Cost: 0.002010\n",
      "Epoch: 1310 W: 1.050714 b: 2.884714 Cost: 0.001916\n",
      "Epoch: 1320 W: 1.049508 b: 2.887456 Cost: 0.001826\n",
      "Epoch: 1330 W: 1.048331 b: 2.890132 Cost: 0.001740\n",
      "Epoch: 1340 W: 1.047182 b: 2.892745 Cost: 0.001658\n",
      "Epoch: 1350 W: 1.046060 b: 2.895296 Cost: 0.001580\n",
      "Epoch: 1360 W: 1.044964 b: 2.897786 Cost: 0.001506\n",
      "Epoch: 1370 W: 1.043895 b: 2.900217 Cost: 0.001435\n",
      "Epoch: 1380 W: 1.042851 b: 2.902590 Cost: 0.001368\n",
      "Epoch: 1390 W: 1.041832 b: 2.904906 Cost: 0.001304\n",
      "Epoch: 1400 W: 1.040837 b: 2.907167 Cost: 0.001242\n",
      "Epoch: 1410 W: 1.039866 b: 2.909375 Cost: 0.001184\n",
      "Epoch: 1420 W: 1.038918 b: 2.911530 Cost: 0.001128\n",
      "Epoch: 1430 W: 1.037992 b: 2.913634 Cost: 0.001075\n",
      "Epoch: 1440 W: 1.037089 b: 2.915688 Cost: 0.001025\n",
      "Epoch: 1450 W: 1.036207 b: 2.917693 Cost: 0.000977\n",
      "Epoch: 1460 W: 1.035346 b: 2.919651 Cost: 0.000931\n",
      "Epoch: 1470 W: 1.034505 b: 2.921561 Cost: 0.000887\n",
      "Epoch: 1480 W: 1.033685 b: 2.923427 Cost: 0.000845\n",
      "Epoch: 1490 W: 1.032884 b: 2.925248 Cost: 0.000805\n",
      "Epoch: 1500 W: 1.032102 b: 2.927025 Cost: 0.000768\n",
      "Epoch: 1510 W: 1.031338 b: 2.928761 Cost: 0.000732\n",
      "Epoch: 1520 W: 1.030593 b: 2.930455 Cost: 0.000697\n",
      "Epoch: 1530 W: 1.029865 b: 2.932109 Cost: 0.000664\n",
      "Epoch: 1540 W: 1.029155 b: 2.933723 Cost: 0.000633\n",
      "Epoch: 1550 W: 1.028462 b: 2.935300 Cost: 0.000603\n",
      "Epoch: 1560 W: 1.027785 b: 2.936838 Cost: 0.000575\n",
      "Epoch: 1570 W: 1.027124 b: 2.938340 Cost: 0.000548\n",
      "Epoch: 1580 W: 1.026479 b: 2.939806 Cost: 0.000522\n",
      "Epoch: 1590 W: 1.025849 b: 2.941238 Cost: 0.000498\n",
      "Epoch: 1600 W: 1.025235 b: 2.942635 Cost: 0.000474\n",
      "Epoch: 1610 W: 1.024635 b: 2.943999 Cost: 0.000452\n",
      "Epoch: 1620 W: 1.024049 b: 2.945331 Cost: 0.000431\n",
      "Epoch: 1630 W: 1.023477 b: 2.946631 Cost: 0.000411\n",
      "Epoch: 1640 W: 1.022919 b: 2.947901 Cost: 0.000391\n",
      "Epoch: 1650 W: 1.022374 b: 2.949140 Cost: 0.000373\n",
      "Epoch: 1660 W: 1.021841 b: 2.950349 Cost: 0.000355\n",
      "Epoch: 1670 W: 1.021322 b: 2.951530 Cost: 0.000339\n",
      "Epoch: 1680 W: 1.020815 b: 2.952683 Cost: 0.000323\n",
      "Epoch: 1690 W: 1.020320 b: 2.953808 Cost: 0.000308\n",
      "Epoch: 1700 W: 1.019836 b: 2.954907 Cost: 0.000293\n",
      "Epoch: 1710 W: 1.019365 b: 2.955979 Cost: 0.000279\n",
      "Epoch: 1720 W: 1.018904 b: 2.957026 Cost: 0.000266\n",
      "Epoch: 1730 W: 1.018455 b: 2.958048 Cost: 0.000254\n",
      "Epoch: 1740 W: 1.018016 b: 2.959045 Cost: 0.000242\n",
      "Epoch: 1750 W: 1.017588 b: 2.960019 Cost: 0.000230\n",
      "Epoch: 1760 W: 1.017169 b: 2.960970 Cost: 0.000220\n",
      "Epoch: 1770 W: 1.016761 b: 2.961898 Cost: 0.000209\n",
      "Epoch: 1780 W: 1.016362 b: 2.962804 Cost: 0.000199\n",
      "Epoch: 1790 W: 1.015973 b: 2.963689 Cost: 0.000190\n",
      "Epoch: 1800 W: 1.015593 b: 2.964552 Cost: 0.000181\n",
      "Epoch: 1810 W: 1.015223 b: 2.965395 Cost: 0.000173\n",
      "Epoch: 1820 W: 1.014861 b: 2.966218 Cost: 0.000165\n",
      "Epoch: 1830 W: 1.014507 b: 2.967022 Cost: 0.000157\n",
      "Epoch: 1840 W: 1.014162 b: 2.967806 Cost: 0.000149\n",
      "Epoch: 1850 W: 1.013825 b: 2.968572 Cost: 0.000142\n",
      "Epoch: 1860 W: 1.013497 b: 2.969319 Cost: 0.000136\n",
      "Epoch: 1870 W: 1.013176 b: 2.970049 Cost: 0.000129\n",
      "Epoch: 1880 W: 1.012862 b: 2.970761 Cost: 0.000123\n",
      "Epoch: 1890 W: 1.012556 b: 2.971456 Cost: 0.000117\n",
      "Epoch: 1900 W: 1.012258 b: 2.972135 Cost: 0.000112\n",
      "Epoch: 1910 W: 1.011966 b: 2.972798 Cost: 0.000107\n",
      "Epoch: 1920 W: 1.011682 b: 2.973445 Cost: 0.000102\n",
      "Epoch: 1930 W: 1.011404 b: 2.974076 Cost: 0.000097\n",
      "Epoch: 1940 W: 1.011133 b: 2.974693 Cost: 0.000092\n",
      "Epoch: 1950 W: 1.010868 b: 2.975295 Cost: 0.000088\n",
      "Epoch: 1960 W: 1.010609 b: 2.975882 Cost: 0.000084\n",
      "Epoch: 1970 W: 1.010357 b: 2.976456 Cost: 0.000080\n",
      "Epoch: 1980 W: 1.010111 b: 2.977016 Cost: 0.000076\n",
      "Epoch: 1990 W: 1.009870 b: 2.977562 Cost: 0.000073\n",
      "Epoch: 2000 W: 1.009636 b: 2.978096 Cost: 0.000069\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[4],[5],[6]])\n",
    "\n",
    "class LinearRegressionModel(nn.Module) :\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(1,1)\n",
    "    \n",
    "  def forward(self, x) :\n",
    "    return self.linear(x)\n",
    "  \n",
    "model = LinearRegressionModel()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "nb_epochs = 2000\n",
    "\n",
    "for epoch in range(nb_epochs +1) :\n",
    "  # H(x) 계산\n",
    "  prediction = model(x_train)\n",
    "  # cost 계산\n",
    "  cost = F.mse_loss(prediction, y_train)\n",
    "  \n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "  \n",
    "  if epoch % 10 == 0 :\n",
    "    W = model.linear.weight.item()\n",
    "    b = model.linear.bias.item()\n",
    "    \n",
    "    print(\"Epoch: {:4d} W: {:.6f} b: {:.6f} Cost: {:.6f}\".format(epoch, W, b, cost.item()))\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608040a1",
   "metadata": {},
   "source": [
    "#### 실활용 예시 _ 기온, 강수량에 따른 채소값 예측모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "665ded6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "X_train: torch.Size([1000, 3]) Y_train: torch.Size([1000, 1])\n",
      "Step:      0 | Loss: 1.706139 | pred[0]: 284.92\n",
      "Step:    500 | Loss: 0.477118 | pred[0]: 621.32\n",
      "Step:   1000 | Loss: 0.111598 | pred[0]: 866.10\n",
      "Step:   1500 | Loss: 0.017912 | pred[0]: 1043.78\n",
      "Step:   2000 | Loss: 0.001888 | pred[0]: 1135.59\n",
      "Step:   2500 | Loss: 0.000473 | pred[0]: 1166.54\n",
      "Step:   3000 | Loss: 0.000421 | pred[0]: 1173.02\n",
      "Step:   3500 | Loss: 0.000421 | pred[0]: 1173.77\n",
      "Step:   4000 | Loss: 0.000421 | pred[0]: 1173.81\n",
      "Step:   4500 | Loss: 0.000421 | pred[0]: 1173.81\n",
      "Step:   5000 | Loss: 0.000421 | pred[0]: 1173.81\n",
      "Step:   5500 | Loss: 0.000421 | pred[0]: 1173.81\n",
      "Step:   6000 | Loss: 0.000421 | pred[0]: 1173.81\n",
      "Step:   6500 | Loss: 0.000421 | pred[0]: 1173.82\n",
      "Step:   7000 | Loss: 0.000421 | pred[0]: 1173.82\n",
      "Step:   7500 | Loss: 0.000421 | pred[0]: 1173.82\n",
      "Step:   8000 | Loss: 0.000421 | pred[0]: 1173.82\n",
      "Step:   8500 | Loss: 0.000421 | pred[0]: 1173.82\n",
      "Step:   9000 | Loss: 0.000421 | pred[0]: 1173.82\n",
      "Step:   9500 | Loss: 0.000421 | pred[0]: 1173.82\n",
      "Step:  10000 | Loss: 0.000421 | pred[0]: 1173.82\n",
      "\n",
      "학습된 모델을 저장했습니다. 파일명: data/saved_model.pt\n"
     ]
    }
   ],
   "source": [
    "# trainModel.py (핵심 부분만 교체/추가)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# 1) 데이터 로드\n",
    "df = pd.read_csv(\"data/price_data.csv\")\n",
    "# 원하는 입력 칼럼을 명시적으로 선택하세요. (예: 평균/최저/최고/강수량)\n",
    "# df.columns 예시를 확인하고 정확히 맞추세요.\n",
    "# print(df.columns)\n",
    "\n",
    "# ★ 현재 3개 입력으로 학습 중이라면 예시:\n",
    "X_np = df[['temperature(°C)', 'rainfall(mm)', 'humidity(%)']].values.astype(np.float32)  # (N,3)\n",
    "y_np = df[['price(₩)']].values.astype(np.float32)                                       # (N,1)\n",
    "\n",
    "# 2) NaN/Inf 가드\n",
    "if np.isnan(X_np).any() or np.isinf(X_np).any():\n",
    "    raise ValueError(\"X에 NaN/Inf가 포함되어 있습니다.\")\n",
    "if np.isnan(y_np).any() or np.isinf(y_np).any():\n",
    "    raise ValueError(\"y에 NaN/Inf가 포함되어 있습니다.\")\n",
    "\n",
    "X = torch.from_numpy(X_np).to(device)\n",
    "y = torch.from_numpy(y_np).to(device)\n",
    "\n",
    "print(\"X_train:\", X.shape, \"Y_train:\", y.shape)  # (N,3) (N,1) 확인\n",
    "\n",
    "# 3) 정규화 (표준화)\n",
    "X_mean = X.mean(dim=0, keepdim=True)\n",
    "X_std  = X.std(dim=0, keepdim=True).clamp_min(1e-6)\n",
    "Xn = (X - X_mean) / X_std\n",
    "\n",
    "# (선택) 타깃 스케일 줄이기 → 안정적 학습에 도움\n",
    "y_scale = 1000.0\n",
    "yn = y / y_scale\n",
    "\n",
    "# 4) 모델\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, 1)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "in_dim = Xn.shape[1]\n",
    "model = LinearRegressionModel(in_dim).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 5) 옵티마이저: Adam 권장 (SGD면 lr 더 낮추세요: 1e-5~1e-6)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "steps = 10000\n",
    "for step in range(steps + 1):\n",
    "    pred = model(Xn)               # 표준화된 입력 사용\n",
    "    loss = criterion(pred, yn)     # 표준화된 타깃 사용\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # (선택) 그래디언트 클리핑으로 폭주 방지\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        # NaN 감시\n",
    "        if torch.isnan(loss):\n",
    "            raise RuntimeError(\"Loss가 NaN입니다. 입력/타깃/학습률을 점검하세요.\")\n",
    "        print(f\"Step: {step:6d} | Loss: {loss.item():.6f} | pred[0]: {(pred[0]*y_scale).item():.2f}\")\n",
    "\n",
    "# 6) 저장 전 폴더 보장\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "torch.save({\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"X_mean\": X_mean.cpu(),\n",
    "    \"X_std\": X_std.cpu(),\n",
    "    \"y_scale\": y_scale\n",
    "}, \"data/saved_model.pt\")\n",
    "print(\"\\n학습된 모델을 저장했습니다. 파일명: data/saved_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2dc78c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "모델이 성공적으로 로드되었습니다. in_dim = 3\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8081\n",
      " * Running on http://172.30.16.182:8081\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [12/Oct/2025 13:53:10] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Oct/2025 13:53:18] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# server\n",
    "\n",
    "from flask import Flask, request, render_template_string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# ---- 모델 아키텍처 ----\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, 1)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# ---- 체크포인트 로드 (state_dict 추출 + in_dim 자동 추론) ----\n",
    "try:\n",
    "    ckpt = torch.load('data/saved_model.pt', map_location=device)\n",
    "    state = ckpt[\"state_dict\"] if isinstance(ckpt, dict) and \"state_dict\" in ckpt else ckpt\n",
    "    in_dim = state[\"linear.weight\"].shape[1]   # (out_features, in_features)\n",
    "\n",
    "    # 데이터는 temperature, rainfall, humidity → in_dim=3 이어야 정상\n",
    "    if in_dim != 3:\n",
    "        print(f\"[경고] 체크포인트가 기대 입력 3과 다릅니다. (in_dim={in_dim})\")\n",
    "    model = LinearRegressionModel(in_dim).to(device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    # 정규화 파라미터(있으면 사용)\n",
    "    X_mean = torch.as_tensor(ckpt[\"X_mean\"], device=device) if isinstance(ckpt, dict) and \"X_mean\" in ckpt else None\n",
    "    X_std  = torch.as_tensor(ckpt[\"X_std\"],  device=device) if isinstance(ckpt, dict) and \"X_std\"  in ckpt else None\n",
    "    y_scale = ckpt[\"y_scale\"] if isinstance(ckpt, dict) and \"y_scale\" in ckpt else 1.0\n",
    "\n",
    "    print(\"모델이 성공적으로 로드되었습니다. in_dim =\", in_dim)\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 'saved_model.pt'를 찾을 수 없습니다.\")\n",
    "    sys.exit(1)\n",
    "except KeyError as e:\n",
    "    print(f\"모델 가중치 키 오류: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Flask 웹 어플리케이션 초기화\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 메인페이지\n",
    "@app.route(\"/\", methods=['GET', 'POST'])\n",
    "def home():\n",
    "    predicted_price = None\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            # CSV 입력 특성에 맞춰 3개만 받습니다.\n",
    "            # CSV: temperature(°C), rainfall(mm), humidity(%), price(₩)\n",
    "            temperature = float(request.form['temperature'])\n",
    "            rainfall    = float(request.form['rainfall'])\n",
    "            humidity    = float(request.form['humidity'])\n",
    "\n",
    "            x = torch.tensor([[temperature, rainfall, humidity]],\n",
    "                             dtype=torch.float32, device=device)  # (1, 3)\n",
    "\n",
    "            # 학습 시 정규화가 있었다면 동일 적용\n",
    "            if X_mean is not None and X_std is not None:\n",
    "                x = (x - X_mean) / X_std\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_pred_norm = model(x)          # (1,1)\n",
    "                y_pred = y_pred_norm * y_scale  # 스케일 복원(없으면 1.0)\n",
    "                predicted_price = f\"{y_pred.item():.2f}\"\n",
    "        except Exception as e:\n",
    "            return f\"에러: {e} <a href='/'>다시 시도</a>\"\n",
    "\n",
    "    return render_template_string(HTML_TEMPLATE, prediction=predicted_price)\n",
    "\n",
    "# 디자인(스타일) 유지, 폼만 3개로 조정\n",
    "HTML_TEMPLATE = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ko\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "<title>배추 가격 예측</title>\n",
    "<style>\n",
    "body { font-family: sans-serif; display: flex; justify-content: center; align-items:\n",
    "center; height: 100vh; background-color: #f0f4f8; }\n",
    "\n",
    ".container { background: white; padding: 2rem; border-radius: 10px; box-\n",
    "shadow: 0 4px 6px rgba(0,0,0,0.1); text-align: center; }\n",
    "h1 { color: #333; }\n",
    ".form-group { margin-bottom: 1rem; }\n",
    "label { display: block; margin-bottom: 0.5rem; color: #555; text-align: left; }\n",
    "input { width: 100%; padding: 0.5rem; border: 1px solid #ccc; border-radius:\n",
    "5px; box-sizing: border-box; }\n",
    "button { padding: 0.75rem 1.5rem; background-color: #007bff; color: white;\n",
    "border: none; border-radius: 5px; cursor: pointer; font-size: 1rem; }\n",
    "button:hover { background-color: #0056b3; }\n",
    ".result { margin-top: 1.5rem; padding: 1rem; border: 2px solid #007bff;\n",
    "border-radius: 5px; }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"container\">\n",
    "<h1>배추 가격 예측</h1>\n",
    "<form method=\"post\">\n",
    "  <div class=\"form-group\">\n",
    "    <label for=\"temperature\">기온 (°C)</label>\n",
    "    <input type=\"text\" id=\"temperature\" name=\"temperature\" required>\n",
    "  </div>\n",
    "  <div class=\"form-group\">\n",
    "    <label for=\"rainfall\">강수량 (mm)</label>\n",
    "    <input type=\"text\" id=\"rainfall\" name=\"rainfall\" required>\n",
    "  </div>\n",
    "  <div class=\"form-group\">\n",
    "    <label for=\"humidity\">습도 (%)</label>\n",
    "    <input type=\"text\" id=\"humidity\" name=\"humidity\" required>\n",
    "  </div>\n",
    "  <button type=\"submit\">예측하기</button>\n",
    "</form>\n",
    "{% if prediction %}\n",
    "<div class=\"result\">\n",
    "  <h3>예측 결과</h3>\n",
    "  <p><strong>예상 배추 가격:</strong> {{ prediction }} 원</p>\n",
    "</div>\n",
    "{% endif %}\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 개발 서버 경고는 정상입니다. 배포 시에는 gunicorn/uwsgi + nginx를 권장합니다.\n",
    "    app.run(host='0.0.0.0', port=8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bd687ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000, Cost: 0.539713 Accuracy 83.33%\n",
      "Epoch  100/1000, Cost: 0.134272 Accuracy 100.00%\n",
      "Epoch  200/1000, Cost: 0.080486 Accuracy 100.00%\n",
      "Epoch  300/1000, Cost: 0.057820 Accuracy 100.00%\n",
      "Epoch  400/1000, Cost: 0.045251 Accuracy 100.00%\n",
      "Epoch  500/1000, Cost: 0.037228 Accuracy 100.00%\n",
      "Epoch  600/1000, Cost: 0.031649 Accuracy 100.00%\n",
      "Epoch  700/1000, Cost: 0.027538 Accuracy 100.00%\n",
      "Epoch  800/1000, Cost: 0.024381 Accuracy 100.00%\n",
      "Epoch  900/1000, Cost: 0.021877 Accuracy 100.00%\n",
      "Epoch 1000/1000, Cost: 0.019843 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]\n",
    "x_train = torch.FloatTensor(x_data) # torch.Size([6, 2])\n",
    "y_train = torch.FloatTensor(y_data) # torch.Size([6, 1])\n",
    "\n",
    "class BinaryClassfier(nn.Module):\n",
    "  def __init__(self) :\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(2,1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "  def forward(self, x) :\n",
    "    return self.sigmoid(self.linear(x))\n",
    "  \n",
    "model = BinaryClassfier()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1) :\n",
    "  hypothesis = model(x_train)\n",
    "  \n",
    "  cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "  \n",
    "  # cost 로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "  \n",
    "  if epoch % 100 == 0 :\n",
    "    prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True\n",
    "    correct_predication = prediction.float() == y_train\n",
    "    accuracy = correct_predication.sum().item() / len(correct_predication) #정확도\n",
    "    print(\"Epoch {:4d}/{}, Cost: {:.6f} Accuracy {:2.2f}%\".format(epoch,nb_epochs,cost.item(),accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2098c3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 [1,4] 일때의 예측값 : tensor([0.0057], grad_fn=<SigmoidBackward0>)\n",
      "tensor([False])\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델에 임의의입력 [1,4] 를 적용하여 값을 검증\n",
    "new_var = torch.FloatTensor([1.0,4.0])\n",
    "pred_y = model(new_var) # forward 연산\n",
    "print(\"훈련 후 입력이 [1,4] 일때의 예측값 :\", pred_y)\n",
    "\n",
    "predition = pred_y >= torch.FloatTensor([0.5])\n",
    "print(predition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d53263d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 이미지 데이터 레이블은 5이다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "mnist.data[0]\n",
    "mnist.target[0]\n",
    "mnist.target = mnist.target.astype(np.int8)\n",
    "X = mnist.data / 255\n",
    "y = mnist.target\n",
    "\n",
    "plt.imshow(X[0].reshape(28,28), cmap='gray')\n",
    "print(\"이 이미지 데이터 레이블은 {:.0f}이다.\".format(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ca77ff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3 Cost: 0.057891\n",
      "Epoch:    2/3 Cost: 0.018430\n",
      "Epoch:    3/3 Cost: 0.015933\n",
      "/n 테스트 데이터에서 예측 정확도 9449/10000 94\n",
      "예측결과 : 2\n",
      "이 이미지 데이터의 정답 레이블은 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=0)\n",
    "\n",
    "# 텐서로 변환\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.Tensor(y_train)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "#TensorDataset 객체 생성\n",
    "\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader 객체 생성\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "model = nn.Sequential()\n",
    "model.add_module(\"fc1\", nn.Linear(28*28*1, 100))\n",
    "model.add_module(\"relu1\", nn.ReLU())\n",
    "model.add_module(\"fc2\", nn.Linear(100,100))\n",
    "model.add_module(\"relu2\", nn.ReLU())\n",
    "model.add_module(\"fc3\", nn.Linear(100,10))\n",
    "# print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "  for data, targets in loader_train :\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(data)\n",
    "    loss = loss_fn(y_pred, targets.long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  print(f\"Epoch: {epoch+1:4d}/{3} Cost: {loss.item():.6f}\")\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "\n",
    "#데이터로더에서 미니배치를 하나씩 꺼내 추록을 수행\n",
    "\n",
    "with torch.no_grad() :\n",
    "  for data, targets in loader_test :\n",
    "    outputs = model(data)\n",
    "    # 추론계산\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    # 정답과 일치한 경우 정답 카운트를 증가\n",
    "    correct += (predicted == targets).sum().item()\n",
    "    \n",
    "# 정확도 출력\n",
    "\n",
    "data_num = len(loader_test.dataset)\n",
    "print(f\"/n 테스트 데이터에서 예측 정확도 {correct:.0f}/{data_num} {100*correct/data_num:.0f}\")\n",
    "\n",
    "index = 2018\n",
    "\n",
    "model.eval()\n",
    "data = X_test[index]\n",
    "ouput = model(data)\n",
    "\n",
    "_, predicted = torch.max(ouput.data, 0) # 확률이 가장 높은 레이블 계산\n",
    "print(f\"예측결과 : {predicted}\")\n",
    "\n",
    "X_test_show = (X_test[index]).numpy()\n",
    "plt.imshow(X_test_show.reshape(28,28), cmap='gray')\n",
    "print(f\"이 이미지 데이터의 정답 레이블은 {y_test[index]:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0ff840c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# relu test\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "relu = nn.ReLU()\n",
    "x = torch.tensor([-2.0, -1.0, 0.0, 2.0, 3.0])\n",
    "print(relu(x))\n",
    "# tensor([0., 0., 0., 2., 3.]) -> 음수 :0, 양수 : 통과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde0a78",
   "metadata": {},
   "source": [
    "#### RNN 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6aa5abc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 8])\n",
      "torch.Size([1, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_size = 5\n",
    "hidden_size = 8\n",
    "\n",
    "# (batch_size, time_steps, input_size)\n",
    "\n",
    "inputs = torch.Tensor(1,10,input_size)\n",
    "cell = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "outputs, _status = cell(inputs)\n",
    "print(outputs.shape) # torch.Size([1, 10, 8])\n",
    "print(_status.shape) # torch.Size([1, 1, 8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langCh-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
