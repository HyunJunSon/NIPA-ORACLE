{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2716cf",
   "metadata": {},
   "source": [
    "## 머신러닝 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8fc7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f33ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tsor = np.arange(7.0)\n",
    "tsor.ndim # 1.    # 텐서의 차원\n",
    "tsor.shape # (7,)  # 텐서의 크기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3576d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsor2 = np.arange(1.0, 13).reshape((4,3))\n",
    "tsor2.ndim #2\n",
    "tsor2.shape # (4,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1dde4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tsor3 = torch.arange(0.0, 7)\n",
    "tsor3.dim() # 1\n",
    "tsor3.shape  # torch.Size([7])\n",
    "tsor3.size() # torch.Size([7])\n",
    "tsor3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 4.,  5.],\n",
       "        [ 7.,  8.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(1,13.0).reshape((4,3))\n",
    "t.dim() #2\n",
    "t.size() # torch.Size([4, 3])\n",
    "t.shape # torch.Size([4, 3])\n",
    "\n",
    "t[:,1]\n",
    "t[:,1].size()\n",
    "t[:,:-1] # 마지막 차원 제외\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1c5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([3,3])\n",
    "m2 = torch.FloatTensor([2,2])\n",
    "m1 + m2 # tensor([5., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcbc1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([1,2])\n",
    "m2 = torch.FloatTensor([3])\n",
    "m1 + m2 # tensor([4., 5.]) 큰 size에 맞춰서 작은 사이즈가 중복되어 생김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342198b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m2 = torch.FloatTensor([[1],[2]]) # 2*1\n",
    "m1 + m2 # tensor([[2., 3.],\n",
    "        #         [5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1aacb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [11.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m2 = torch.FloatTensor([[1],[2]]) # 2*1\n",
    "\n",
    "m1.matmul(m2).shape # torch.Size([2, 1]) 내적 (dot 연산) -> matrix multiplication \n",
    "(m1 @ m2).shape # 위와 같은 연산\n",
    "torch.matmul(m1,m2)\n",
    "# torch.dot(m1,m2) 벡터끼리의 내적만 지원함 행렬곱은 안됨 -> 1D 전용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d77b36",
   "metadata": {},
   "source": [
    "#### 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c2b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 3.5000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([1,2])\n",
    "t.mean() # tensor(1.5000)\n",
    "m1 = torch.FloatTensor([[1,2],[3,4]]) # 2*2\n",
    "m1.mean()\n",
    "\n",
    "m1.mean(dim=0 ,dtype=torch.float) # tensor([2., 3.])\n",
    "m1.mean(dim=1 ,dtype=torch.float) # tensor([1.5000, 3.5000])\n",
    "# m1.mean(dim=2 ,dtype=torch.float) # Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
    "\n",
    "# dim=0이면 0번째 축(행 방향) 을 없애면서 계산,\n",
    "# dim=1이면 1번째 축(열 방향) 을 없애면서 계산\n",
    "m1.mean(dim=-1 ,dtype=torch.float) # tensor([1.5000, 3.5000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a46c61",
   "metadata": {},
   "source": [
    "#### 덧셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba69c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 7.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.FloatTensor([[1,2],[3,4]])\n",
    "t2.sum() #tensor(10.)\n",
    "t2.sum(dim=0) # tensor([4., 6.])\n",
    "t2.sum(dim=1) # tensor([3., 7.])\n",
    "t2.sum(dim=-1) # tensor([3., 7.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96421c8e",
   "metadata": {},
   "source": [
    "#### max, arxmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e8495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.FloatTensor([[1,2],[3,4]])\n",
    "t3.max() # tensor(4.)\n",
    "t3.max(dim=0) # torch.return_types.max(values=tensor([3., 4.]),indices=tensor([1, 1])) # indice= 최대값위치\n",
    "t3.max(dim=1) # torch.return_types.max(values=tensor([2., 4.]),(indices=tensor([1, 1]))\n",
    "\n",
    "t3.max(dim=0)[0] # tensor([3., 4.]) -> tensor\n",
    "t3.max(dim=0)[1] # tensor([1, 1]) -> indice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a70194",
   "metadata": {},
   "source": [
    "#### view - 원소의 수를 유지하며 텐서 크기 변경 (np.reshape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764e47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tt = np.arange(0,12).reshape((4,3))\n",
    "tt\n",
    "\n",
    "ft = torch.FloatTensor(tt)\n",
    "\n",
    "# tensor([[ 0.,  1.,  2.],\n",
    "#         [ 3.,  4.,  5.],\n",
    "#         [ 6.,  7.,  8.],\n",
    "#         [ 9., 10., 11.]])\n",
    "\n",
    "\n",
    "ft.shape # torch.Size([4, 3])\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba3e319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.],\n",
       "        [ 2.,  3.],\n",
       "        [ 4.,  5.],\n",
       "        [ 6.,  7.],\n",
       "        [ 8.,  9.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47f1825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.view([-1,1,3]).shape # torch.Size([4, 1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044b6ca",
   "metadata": {},
   "source": [
    "#### squeeze -1 차원 제거, unsqueeze +1 차원추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4ac5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = ttt = torch.arange(1,4).reshape((3,1))\n",
    "\n",
    "ttt.shape #torch.Size([3, 1])\n",
    "ttt.squeeze().shape # torch.Size([3])\n",
    "\n",
    "\n",
    "tttt = torch.arange(1,4).reshape((3,1))\n",
    "# tensor([[1],\n",
    "#         [2],\n",
    "#         [3]])\n",
    "# torch.Size([3, 1])\n",
    "\n",
    "tttt.unsqueeze(0) # 인덱스가 0부터 시작하므로 0은 첫번째 차원을 의미한다.\n",
    "\n",
    "# tensor([[[1],\n",
    "#          [2],\n",
    "#          [3]]])\n",
    "# torch.Size([1, 3, 1])\n",
    "\n",
    "tttt.unsqueeze(1)\n",
    "\n",
    "# tensor([[[1]],\n",
    "\n",
    "#         [[2]],\n",
    "\n",
    "        # [[3]]])\n",
    "tttt.unsqueeze(1).shape\n",
    "\n",
    "#torch.Size([3, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c34597b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tttt.unsqueeze(-1).shape # torch.Size([3, 1, 1])\n",
    "\n",
    "tttt.view(1,-1) # torch.Size([1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460bdb0a",
   "metadata": {},
   "source": [
    "#### 타입캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d809128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = torch.LongTensor([1,2,3,4]) #tensor([1, 2, 3, 4])\n",
    "ft.float() # tensor([1., 2., 3., 4.])\n",
    "\n",
    "bt = torch.ByteTensor([True, False, False, True]) # tensor([1, 0, 0, 1], dtype=torch.uint8)\n",
    "bt.long() # tensor([1, 0, 0, 1])\n",
    "bt.float() # tensor([1., 0., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe31633",
   "metadata": {},
   "source": [
    "#### tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7407cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "y = torch.FloatTensor([[5,6],[7,8]])\n",
    "\n",
    "torch.cat((x,y)) # dim= 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf9f4cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 5., 6.],\n",
       "        [3., 4., 7., 8.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39978e8a",
   "metadata": {},
   "source": [
    "#### 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38524749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "torch.stack((x,y,z)) #1+1+1 차원 -> 2차원\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5441c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x.unsqueeze(0),y.unsqueeze(0), z.unsqueeze(0))) # 위와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dab2b",
   "metadata": {},
   "source": [
    "#### one_like, zeros_like -0, 1로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "396b34a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.FloatTensor([[0,1,2],[2,1,0]]) # 2 * 3 텐서\n",
    "torch.ones_like(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54be3796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f03d90",
   "metadata": {},
   "source": [
    "#### in place operation 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0670f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "x.mul(2)\n",
    "x # 원본은 그대로임\n",
    "x.mul_(2)\n",
    "x # 원본이 변경됨( in_place version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00198eef",
   "metadata": {},
   "source": [
    "## 선형회귀와 다중미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]]) # 3*1\n",
    "y_train = torch.FloatTensor([[2],[4],[6]]) # 3*1\n",
    "\n",
    "x_train.shape # torch.Size([3, 1])\n",
    "\n",
    "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True) # tensor([0.], requires_grad=True)\n",
    "W3 = torch.zeros(0, requires_grad=True) # tensor([], requires_grad=True)\n",
    "W2 = torch.zeros((3,3), requires_grad=True) \n",
    "\n",
    "# tensor([[0., 0., 0.],\n",
    "#         [0., 0., 0.],\n",
    "#         [0., 0., 0.]], requires_grad=True)\n",
    "\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# 경사하강법 적용할 optimizer 함수 SGD를 정의\n",
    "\n",
    "optimizer = optim.SGD([W,b],lr=0.01) # SGD - Stochastic Gradient Descent\n",
    "\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# tensor([[0.],\n",
    "#         [0.],\n",
    "#         [0.]], grad_fn=<AddBackward0>)\n",
    "\n",
    "# 비용함수 = average(가설값 - 실제데이터)^2\n",
    "\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "# tensor(18.6667, grad_fn=<MeanBackward0>)\n",
    "\n",
    "# gradient 0으로 초기화\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# 비용함수를 미분하여 gradient 계산\n",
    "\n",
    "cost.backward()\n",
    "\n",
    "# W, b 를 업데이트\n",
    "\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "15525f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 W: 0.186667, b: 0.080, Cost: 18.666666\n",
      "Epoch  100/2000 W: 1.745691, b: 0.578, Cost: 0.048171\n",
      "Epoch  200/2000 W: 1.800099, b: 0.454, Cost: 0.029767\n",
      "Epoch  300/2000 W: 1.842860, b: 0.357, Cost: 0.018394\n",
      "Epoch  400/2000 W: 1.876473, b: 0.281, Cost: 0.011366\n",
      "Epoch  500/2000 W: 1.902897, b: 0.221, Cost: 0.007024\n",
      "Epoch  600/2000 W: 1.923668, b: 0.174, Cost: 0.004340\n",
      "Epoch  700/2000 W: 1.939996, b: 0.136, Cost: 0.002682\n",
      "Epoch  800/2000 W: 1.952832, b: 0.107, Cost: 0.001657\n",
      "Epoch  900/2000 W: 1.962921, b: 0.084, Cost: 0.001024\n",
      "Epoch 1000/2000 W: 1.970853, b: 0.066, Cost: 0.000633\n",
      "Epoch 1100/2000 W: 1.977087, b: 0.052, Cost: 0.000391\n",
      "Epoch 1200/2000 W: 1.981989, b: 0.041, Cost: 0.000242\n",
      "Epoch 1300/2000 W: 1.985842, b: 0.032, Cost: 0.000149\n",
      "Epoch 1400/2000 W: 1.988870, b: 0.025, Cost: 0.000092\n",
      "Epoch 1500/2000 W: 1.991251, b: 0.020, Cost: 0.000057\n",
      "Epoch 1600/2000 W: 1.993122, b: 0.016, Cost: 0.000035\n",
      "Epoch 1700/2000 W: 1.994594, b: 0.012, Cost: 0.000022\n",
      "Epoch 1800/2000 W: 1.995750, b: 0.010, Cost: 0.000013\n",
      "Epoch 1900/2000 W: 1.996659, b: 0.008, Cost: 0.000008\n",
      "Epoch 2000/2000 W: 1.997374, b: 0.006, Cost: 0.000005\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]]) # 3*1\n",
    "y_train = torch.FloatTensor([[2],[4],[6]]) # 3*1\n",
    "\n",
    "x_train.shape # torch.Size([3, 1])\n",
    "\n",
    "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True) # tensor([0.], requires_grad=True)\n",
    "\n",
    "\n",
    "# tensor([[0., 0., 0.],\n",
    "#         [0., 0., 0.],\n",
    "#         [0., 0., 0.]], requires_grad=True)\n",
    "\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# 경사하강법 적용할 optimizer 함수 SGD를 정의\n",
    "\n",
    "optimizer = optim.SGD([W,b],lr=0.01) # SGD - Stochastic Gradient Descent\n",
    "\n",
    "nb_epochs = 2000 # 원하는 만큼 경사하강법을 반복\n",
    "\n",
    "for epoch in range(nb_epochs +1) :\n",
    "    \n",
    "    hypothesis = x_train * W + b\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#   100번 마다 로그 출력\n",
    "    if epoch % 100 == 0 :\n",
    "      print(\"Epoch {:4d}/{} W: {:3f}, b: {:.3f}, Cost: {:6f}\".format(epoch, nb_epochs, W.item(), b.item(), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7c871a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost:29661.800781\n",
      "Epoch  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost:1.563628\n",
      "Epoch  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost:1.497595\n",
      "Epoch  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost:1.435044\n",
      "Epoch  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost:1.375726\n",
      "Epoch  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost:1.319507\n",
      "Epoch  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost:1.266222\n",
      "Epoch  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost:1.215703\n",
      "Epoch  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost:1.167810\n",
      "Epoch  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost:1.122429\n",
      "Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost:1.079390\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "# 훈련 데이터\n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 가중치 w와 편향 b 초기화\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD( [ w1, w2, w3, b] , lr=0.00001 )\n",
    "\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "# H(x) 계산\n",
    "  hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "# cost 계산\n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "# cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "# 100번마다 로그 출력\n",
    "  if epoch % 100 == 0:\n",
    "    print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost:{:.6f}'.format(\n",
    "\n",
    "  epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(),cost.item()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "[93, 88, 93],\n",
    "[89, 91, 80],\n",
    "[96, 98, 100],\n",
    "[73, 66, 70]])\n",
    "\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "# H(x) 계산, 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
    "  hypothesis = x_train.matmul(W) + b\n",
    "  \n",
    "  # cost 계산\n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "  # cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "\n",
    "print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "))\n",
    "# 학습하여 산출된 가중치( W1~3 과 b값) 에 대하여 임의의 입력 값 적용\n",
    "# no_grad() block 내 모든 연산수행시 역전파(기울기 계산) 비활성화\n",
    "#\n",
    "with torch.no_grad():\n",
    "# 예측하고 싶은 임의의 입력값\n",
    "  new_input = torch.FloatTensor([[75, 85, 72]])\n",
    "  prediction = new_input.matmul(W) + b\n",
    "  \n",
    "print('Predicted value for input {}: {}'.format(new_input.squeeze().tolist(),prediction.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1496e",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch는 기본적으로 모든 Tensor 연산을 추적(trace) 합니다.\n",
    "왜냐하면 backward()로 역전파(gradient 계산)를 하기 위해서죠.\n",
    "\n",
    "하지만 예측할 때는 더 이상 학습하지 않으므로,\n",
    "기울기를 계산할 필요가 없습니다 → 메모리 절약 + 속도 향상.\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langCh-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
